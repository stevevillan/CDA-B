OPERATING SYSTEM FUNDAMENTALS
A.	INTRODUCTION
This lesson provides Cyber Defense Analyst (CDA) trainees with an introduction to the Persistent Cyber Training Environment (PCTE) platform, and a strong set of foundational knowledge regarding the operation of modern Operating Systems (OS). Trainees utilize the PCTE lab environment to explore OS concepts, and begin developing an investigative skillset by performing a simple digital forensics investigation. At the conclusion of the lesson, trainees are prepared to navigate the PCTE lab environment, and are ready to participate in the rest of the CDA courses.
Estimated time to complete: 2.0 hours

B.	ENABLING OBJECTIVES
Upon successful completion of this section, you will be able to:
1.1.1	DEMONSTRATE ability to operate within PCTE lab environment
1.1.2	DISCUSS the OSs of the CDA-Basic course
1.1.3	IDENTIFY the fundamentals of several different OSs and their corresponding internals
1.1.4	DEMONSTRATE basic file forensics
1.1.5	DISCUSS forensic principles

C.	TOPIC OUTLINE
•	Introduction to PCTE
•	OS Fundamentals
○	OS Architecture
○	Processes and process management
○	Memory management
○	File systems and file management
○	Network management
○	Peripheral device management
•	Forensic investigations
 
D.	TOOLKIT

Process Explorer



Process Explorer is a product in the Sysinternals suite of products. It allows for viewing information about running processes in a more granular level than Task Manager.

ExifTool



ExifTool is a platform-independent Perl library and command-line application used to read, write, and edit meta information in a wide variety of files.

Command Line Interface


Command Line Interface (CLI), for the purposes of this lesson, is a generic term for the interface used to execute commands on a system. CLIs include PowerShell terminals, CMD.exe on Windows, Bash, and others.
 



INFORMATION SHEET 1-1

LESSON 1 — OPERATING SYSTEM FUNDAMENTALS

2.	Introduction to PCTE
All training through the CDA-Basic, CDA-Host, and CDA-Network courses of instruction are hosted in and use the PCTE. PCTE's mission is to support United States Cyber Command (USCYBERCOM) by enabling a critical need for the Department of Defense (DoD) and Joint Cyberspace Operations Forces (JCOF) to train at the individual, team, and force level.
PCTE is a training platform supporting standardized JCOF individual sustainment training, team certification, mission rehearsal, and conduction of collective training exercises. It leverages existing connectivity to facilitate the sharing of resources, and provides additional cyber maneuver space. PCTE enables realistic training with variable conditions to increase readiness and lethality of our Cyberspace Operations Forces (COF), while standardizing, simplifying, and automating the training management process.
In short, PCTE is a platform where USCYBERCOM forces and their partners can train, assess, certify, and rehearse. It provides an avenue to create and host individual and team training content, and the ability to build complex cyber ranges in support of that training content and other exercise events.

Figure 1.1-1
NOTE: This introductory content on PCTE reflects PCTE version 3.05 on Regional Compute and Storage 06 (RCS06). You can think of an RCS as a regional datacenter. Some features and capabilities that are displayed may include minor changes, if you are using a newer version of PCTE. Some webpages depicted in screenshots throughout this lesson may reflect slight differences due to PCTE's varying user roles and their associated permissions.
 
The lobby shown in Figure 1.1-1 is the main landing page for PCTE users. The cards displayed in the lobby for most users include Portal, Chat, Contact Support, and Wiki. Notice that each card has a brief description and current status listed. Any card can be selected to bring you to that area or service within the PCTE platform.
Select a card shown in Figure 1.1-2 to open a new tab. Select the icon in the top right corner — appears by hovering over that section — of the card to open the page in the same tab.

Figure 1.1-2
Select the Portal card to open the portal web application known as the Home dashboard, as shown in Figure 1.1-3.

Figure 1.1-3
 
Home Dashboard
The Home dashboard contains two sections by default: My Events and Featured Content. Within My Events, there are Upcoming, Active, and Completed events. Upcoming includes the day's lessons each morning while attending the CDA course, and Completed displays a history of lessons completed along with a summary of the completion percentage for each lesson. You can also access the Event Calendar from My Events.
The next section is Featured Content, which gives access to the Content Catalog and some
Featured Content Modules.
The Home dashboard also contains analytics of the trainees' Individual Structured Content Events and Team Structured Content Events. There is also an option to View Full Profile underneath the analytics section.
Purple Ribbon

Figure 1.1-4
The Purple Ribbon sits on the left side of the PCTE interface. It contains various options and links such as Create, Search, Browse Content Catalog, Background Activity Monitor, Notifications, and My Profile as shown in Figure 1.1-5. Many of the options in My Profile are the same in the various cards on the PCTE Lobby page.

Figure 1.1-5
 
Mattermost Chat
Mattermost chat allows the trainee to participate in public and private chat channels as well as direct messages with other trainees.
Mattermost chat can be accessed two different ways; by selecting the Chat card in the Lobby, as seen in Figure 1.1-6, or by selecting the user icon from the Purple Ribbon, and then selecting the Chat option.

Figure 1.1-6

Figure 1.1-7
Figure 1.1-7 illustrates the Public Channels, Private Channels, Direct Messages, and other various options available in Mattermost Chat.
NOTE: When opening Mattermost chat, ensure you are joining your specific team.

3.	Content Modules, Structured Content Plans, and Structured Content Events
A Content Module (CM) is simply an individual training module that has specific tasks and may have a specific network range attached to it. The content you are reading right now is contained within a CM.
 
A Structured Content Plan (SCP) is comprised of one or more CMs. To access a CM, it must be part of a SCP. This construct allows training managers to mix and match lessons to create new training pipelines from existing content. There are other settings involved with SCPs that are outside of the scope of this lesson.
A Structured Content Event (SCE) is simply a scheduled or running instance of a SCP. Training managers can add participants and managers to SCEs. You are currently enrolled in an SCE, if you are reading this lesson in PCTE.
Interacting with a SCE
The content of each SCE is presented on task cards, which can be either information tasks (indicated with i) or question tasks (indicated with ?). Tasks are grouped together logically into separate task chains containing related information, as shown in Figure 1.1-8. In effect, task chains function like chapter headers, and tasks like sections within each chapter.
Each information task contains specific content, such as text and/or images. Questions tasks can also have informational material, but ultimately end with a knowledge check on the content covered in previous tasks.
You can select a specific task from the list to view it, or select the Next or Previous arrows to advance or revisit previous tasks. If you perform the actions listed at this time, your current spot in the lesson is lost, and revisiting the task is required.
NOTE: In some cases, you may not be able to advance to future tasks until you have entered a response to the current question task.

Figure 1.1-8
Both question and information tasks may contain a Documents panel and a Virtual Machine (VM) Access panel on the right side of the page, as shown below in Figure 1.1-9 and Figure 1.1-
10. The Documents panel contains attached files that are relevant to the content, while the VM Access panel is used to access VMs required for the task. Any given task only includes documents or VMs when appropriate to its content. VMs that are included are those that you need to access to perform a task or action but in no way represent the full range that might be used within a lesson. As an example, the trainee often accesses the cda-win-hunt or cda-lin-hunt VMs, and uses those systems to perform actions — or access systems — in the greater CDA range. For example, in Figure 1.1-10, the trainee is only provided a means to access those two
 
virtual machines as those are the only systems that the trainee should need simulated console access to during this task.

Figure 1.1-9

Figure 1.1-10
Some images within the training content in PCTE are not easily viewable in the default view. For a larger view of any image on a task, right-click the image and select Open Image in New Tab, as shown in Figure 1.1-11. The name of the Open Image in a New Tab option may vary slightly, depending on your web browser.

Figure 1.1-11
 
4.	Interacting with the Range
The range is where the lesson’s associated VMs are located. VMs and various range options and features are discussed later in more detail.
To demonstrate how to access the range within a lesson, consider the lesson Executing Network- based Threat Hunts shown in Figure 1.1-12.

Figure 1.1-12
Enrolling and starting the event displays the screen shown in Figure 1.1-13.

Figure 1.1-13
 
The VM Access panel shown in Figure 1.1-14 displays the various VMs associated with the current lesson that the trainee needs access to. The username and password for each VM is displayed below the VM name. Select Open Console to open the VM in a new window. CTRL- click or CMD-click opens the VM in a new tab within the same window.

Figure 1.1-14
Once Open Console is selected, the VM opens and displays a few options at the top of the window, as shown in Figure 1.1-15.

Figure 1.1-15
The options help you interact with the VM, letting you display a virtual keyboard, execute various Commands (Control-Alt-Delete or Send Text To Client), and access the VM’s clipboard to copy text out of the VM. Figure 1.1-16 shows how to Send Text To Client.

Figure 1.1-16
 
Figure 1.1-17 shows how to copy text out of the VM.
NOTE: Copying content directly out of the VM in this fashion is only available on certain VMs. Most VMs with a Graphical User Interface (GUI) have this feature enabled.

Figure 1.1-17
Range Considerations
The ranges and associated VMs within PCTE rely on different automation and orchestration technologies to provide a realistic training and certification environment. The platform provides automatic configuration capabilities, simulated internet, and user emulation, which may be necessary for normal range function. These advanced capabilities leave artifacts behind in the ranges that may be visible during this course. These occurrences, also known as range-isms, are called out periodically in lessons to remind you of their presence. You must ignore or avoid interacting with these items. At best, they are minor annoyances that take up some extra space; at worst, interacting with them may cause the range to fail and require a redeployment. Some of these range-isms include:
•	The 10.0.0.0/8 subnet is used for range management and configuration.
WARNING: Do not interact with this subnet or it may cause an error in the range.
•	There are several files, directories, and processes that are related to normal range operation. These items are off-limits and should not be interfered with. If uncovered within the context of an investigation, these items can be safely ignored, as they are not relevant to the investigation.
○	systeminit.exe and all files related to this binary
○	java.exe listening on port 49999 & 49998
○	java.exe communicating over port 5762, 15672, & 27017
○	Advanced Message Queuing Protocol (AMQP) listening on port 5672
○	Software or files located in C:\Program Files (x86)\Lincoln\
○	Software or files located in C:\ProgramData\staging\
○	Software or files located in C:\Program Files\Puppet Labs\
○	Software or files located in C:\ProgramData\PuppetLabs\
○	Software or files located in C:\Program Files (x86)\SimSpace\
○	ruby.exe on Windows and ruby on Linux
 
5.	OS Architecture
According to Oxford Languages Dictionary, an OS is the software that supports a computer's basic functions, such as scheduling tasks, executing applications, and controlling peripherals. The OS controls the use of hardware, such as the Central Processing Unit (CPU), memory, disk, and peripheral devices, and allows users and other software to make use of the system without directly speaking the language of the underlying hardware. This makes it easier for application developers and programmers to use the system to accomplish a variety of tasks.
Many modern computer systems have an OS structure similar to the one outlined in Figure 1.1-
18. Note that this is just an abstraction of an OS — key implementation details for Windows and Linux OSs are presented later in this lesson.

Figure 1.1-18
User Mode vs. Kernel Mode
There are two modes of operation built into a system’s CPU: user mode and kernel mode.
In user mode, the code being executed can only run a limited set of safe instructions, and cannot directly access any of the system’s hardware. In kernel mode, the code being executed by the CPU has unrestricted access to all of the system’s hardware. This access includes the ability to execute any CPU instruction and access any memory address. If misused, this ability can be incredibly dangerous to the system’s state, and can even cause a total system halt. When a CPU is operating in either of these modes, it is said to be operating in user space or kernel space, respectively.
In most modern OSs, a small set of OS programs are allowed to run in kernel mode. Everything else, even applications opened by an administrator, run in user mode.
System Calls
This dual-mode design presents a major issue — a program running in user mode needs to access the system’s hardware in order to function, but is not allowed to do so. For example, a program needs access to the system’s memory and CPU in order to execute, and may also require the ability to read or write files to disk, send data across a network link, or communicate with an external peripheral device. In order to solve this problem, client applications must ask the OS for help by making a system call (or syscall).
 
System calls are the only way for a user mode application to be temporarily granted the high- privileged access available to kernel mode. System calls are implemented by the OS in a safe and controlled manner, barring a critical software bug in the system call code, of course. This means that the execution of a system call should never be dangerous to the system state.
System Call Example
Consider a user mode program that wishes to access a file.
The user mode program makes a system call to the OS; the system call contains details about the file that the program wishes to access. Upon receipt of the system call, the OS triggers an interrupt within the CPU — the CPU saves the state of the original user mode program, and performs a context switch from user mode to kernel mode. After this context switch, the OS is given control to determine if the user mode program that performed the system call should be allowed access to the specified file. If the OS determines that this access is allowed, the OS executes a safe set of instructions to perform the file access for the user mode program — the original user mode program has no control over the instructions that the OS executes during this step. After performing the file access, the OS instructs the CPU to perform another context switch from kernel mode back to user mode. Lastly, the OS returns execution back to the original user mode program, allowing it to resume its operations, and passes the original program details about the file access.
This system call pattern is used frequently within an OS to allow user mode programs to access hardware resources and perform a variety of other tasks. If this access was not implemented in a safe and controlled fashion, a single unstable program could make the system completely unusable.
System Calls vs. Library Calls
Another important concept is the difference between system calls and library calls. A library is a software module that implements some functionality and makes that functionality available to other programs by exposing it through an interface. For example, most OSs and programming languages are shipped with an embedded networking library, which allows an application to utilize networking without worrying about the low-level implementation details. To utilize the networking library, an application needs to load the library’s code and then call the functions within the library that represent the tasks it wants to perform. Continuing the example, an application would call some sort of create() function within the library to create a network connection, and some send() function to send data over that connection. Finally, the application calls some close() function to tear down the connection and free up system resources.
So far, library calls should sound extremely similar to system calls; both types of calls are implemented via a callable interface, and abstract away lower-level implementation details so that calling applications have no need to worry about them. The main difference between system and library calls is that system calls are specifically used to ask the OS to perform an action that requires kernel mode execution, and as such, causes a software interrupt in the CPU. Library calls do not necessarily perform any actions within kernel mode, and instead simply abstract away the implementation of a task.
In many OSs, system calls are actually wrapped within library calls. The networking library presented earlier is a perfect example of this: A user mode application calls the library’s send()
 
function, which in turn must make a system call to the OS to physically send data out over the system’s networking interface hardware.
Protection Rings
The user and kernel modes of execution are built directly into the CPU’s hardware. In addition to this, many OSs implement a model of hierarchical privileges within the OS software itself. This is usually done through the implementation of a protection ring model. In this model, ring 0 represents the operations with the highest privileges over the system (CPU kernel mode operations). Incrementally higher rings represent operations with fewer privileges (extending up to ring 3 in most common OSs). Usually, ring 3 is used to represent CPU user mode operations. Figure 1.1-19 shows a common abstracted layout of protection rings.

Figure 1.1-19 — Image from Wikipedia’s Protection ring page, CC BY-SA 3.0
Navigating Protection Rings
When lower-privileged rings desire access to higher-privileged resources, they must use a system call, library call, or similar mechanism. For example, if a user mode application wants to communicate with a peripheral device, it must make a call to the device driver for that device.
The device driver usually runs in a higher-privileged ring than the application that called it, and is responsible for safely implementing the instructions that allow the system to communicate with the peripheral device. These device drivers may need to execute their own calls, some of which may be system calls, in order to move to higher-privileged rings and fully perform their intended function.
This design means that applications in higher-privileged rings have more control over the system, and consequently, more responsibilities. Applications in higher-privileged rings need to make sure that they implement code in a safe and secure way, so that the state of the system is not compromised.
 
6.	The Kernel
Up until now, OS has been used to generally refer to the software that has control over the system’s hardware. In truth, only a small component of the system truly has this level of control. The kernel is the aptly-named central component of the OS. During the system’s boot process, the kernel program is loaded into a protected area of memory and remains loaded as long as the system is powered on. Unsurprisingly, most kernel code executes in kernel mode within the CPU.
At a minimum, the kernel facilitates the execution of software instructions by the system’s hardware — a simple kernel may only execute a single set of software instructions that are hard- coded into the kernel, and may not allow any other instructions to ever be executed on that particular system. In larger OSs such as Windows, Linux, and MacOS, the kernel provides additional functions such as system resource management and security.
Most modern OSs provide the following capabilities within their kernels:
•	Process management
•	Memory management
•	File management
•	Peripheral and Input/Output (I/O) device management
•	Security management
7.	Process Management
In a modern system, the kernel must be capable of executing code from many different programs, potentially concurrently. To handle this, the kernel instantiates a program executable into a process, then assigns system resources to the process. Process management functions include process creation, execution, termination, modifying system resources (including memory) given to processes, and the scheduling of process threads for execution within the CPU of the system.
Programs, Executables, Processes and Threads
The terms program, executable, process, and thread have clear definitions when discussing OSs, though they are frequently misused in common language.
A program is a set of human-readable instructions that are intended for eventual execution on a computer. Programs are often referred to as source code.
An executable — also known as an image — is a type of file that contains machine instructions that a CPU can actually execute; these instructions are written in a low-level machine language, like assembly. The process of compiling a program involves the translation of the human- readable program source code into corresponding machine instructions, which are then saved as an executable file.
A process is an instance of a running executable that the kernel has loaded into memory and started executing. Several processes can be instantiated from the same executable, though they do not need to be in the same state — for example, two separate web browser windows can be open to different websites at the same time. The kernel assigns system resources, such as memory, to each process.
 
A thread is the smallest unit within a process that can be assigned for execution on the CPU. A process may contain multiple threads, each of which share the pool of system resources that the kernel has allocated to the process. In systems that support it, multithreading or multitasking may allow a process to execute multiple threads concurrently.
Process Structure in Memory
During process creation, the OS allocates a block of memory to be used by that process. All of that process’s execution of code operations occurs within this memory block, which is divided into five main parts: text, data, Block Started by Symbol (BSS), heap, and stack. An additional piece of a process’s memory is reserved for use by the OS, and is used when the OS takes operations to manage that process.
•	Text: Contains the machine instructions loaded from the executable. This is the actual set of instructions that the CPU executes.
•	Data: Stores any variables that were initialized by the programmer or compiler. The initialization process requires the compiler to know how much memory is needed to store the variable, as well as the initial, non-zero value of the variable.
•	BSS: Used to store variables that have been instantiated, but not initialized. This means that the compiler is able to determine how much memory is needed to store a variable, but the program has not set its value, or has set its value explicitly to zero.
•	Heap: Used to dynamically allocate memory for variables whose sizes cannot be known until runtime, i.e., the actual execution of the program. This usually occurs when the size of the variable differs each time the program is run, so the compiler cannot assign a chunk of memory to the variable right off the bat. The heap can freely grow and shrink during program execution.
•	Stack: Last In, First Out (LIFO) data structure used to store stack frames, which contain information about the current execution state of the process. If a process has multiple threads, each thread is given its own stack. As an example, imagine that a thread is currently executing function1(), which contains a call to another function, function2(). When the call to function2() occurs, the current state of function1() is saved into the stack frame for function1() and placed on top of the stack. Then, a new stack frame is created to initialize function2(), itself being placed on top of the stack. When function2() eventually completes, execution is returned to function1() by loading the saved function1() stack frame, which includes loading the code within function1() that lies directly after the call to function2().
 
Figure 1.1-20 shows how a process is laid out within memory. In this figure, the process was allocated a 4 Gigabyte (GB) block of memory, a standard amount for 32-bit systems to allocate to each process. If this sounds like way too much memory for the system to be allocating to a single process, you are correct! This is discussed in further detail in the Memory Management section of this lesson. The sizes of each of the memory sections can differ between executables; for example, two processes may store different amounts of data within the heap. Two processes that were created from the same executable may also differ wildly, depending on the current state of each running process.

Figure 1.1-20 — Image from Gabriele Tolomei’s blog post
In-Memory Layout of a Program (Process)

8.	Lifecycle of a Process
Processes are individual running instances of program executables, and are used by the system to bundle execution threads together with their associated system resources. As such, the concept of a process is used extensively when discussing many different types of computer-related tasks.
From a CDA perspective, a deep understanding of how processes work should be considered a key competency of any CDA.
The OS is responsible for creating, managing, and scheduling processes for execution on the CPU as they proceed throughout their lifecycle. The management of process execution on a system relies heavily on a process’s state. There are five main states that a process can be in, though specific OSs may use more granular states than those described.
•	When in the Created or New state, processes are waiting to be loaded into main memory (Random Access Memory [RAM]). The OS has not yet allocated system resources to the process, or is just beginning to allocate these resources.
•	A process in the Ready or Waiting state has been fully loaded and is waiting to be scheduled for execution. Multiple processes are generally in this state at a given time.
•	A Running process is one that is currently running on one of the CPU’s hardware cores, in either kernel mode or user mode. Processes scheduled to run in the CPU do so for a short while, before being swapped out with another process that is in the Ready state. A Running process that is swapped out of the CPU generally returns to the Ready state.
 
•	A Blocked process is waiting for an event that is outside of its control to occur. For example, a process that is waiting for an incoming network connection might be in the Blocked state while it waits for the connection to occur. Upon receiving the connection, the OS moves that process from Blocked to Running so it can handle the incoming connection.
•	A Terminated process has completed its execution, or was explicitly killed by some other process or system action. Killing a process is a common phrase when discussing process termination.
Process Termination Complications
A terminated process must wait for its parent process to read its exit status before the OS can free its assigned Process Identifier (PID) for use elsewhere. Until the parent reads its child’s exit status, the child process continues to exist in the Terminated state. The name for such a process is a zombie process. Depending on the specifics of the parent process, a zombie process may continue to exist indefinitely.
An orphan process is a child process whose parent process has terminated before it. This may lead to the child process being adopted by a new parent process — usually the root process of the system or another process specifically delegated by the OS to adopt orphan processes — but not always.
Process Identifiers
When a process is created — also referred to as spawning a process — the OS assigns that process a number in order to identify that process within the system. This number is known as a PID. One key thing to note about PIDs is that they are unique only for currently executing processes within a single system — two different systems may assign the same PIDs to different processes, and a system may reuse a PID if it is not currently being used.
Many systems take action against a process or report on the state of a process by referencing that process’s PID. For example, the kill command can be used to terminate a process on a Linux machine, but must be given the PID of a process in order to take action upon it.
Process Trees
Within an OS, processes are never created out of thin air; some trigger usually has to occur in order for a new process to be created by the OS. This trigger may be caused by a human user telling the system to launch a process directly, or it may be caused by other code that is currently executing somewhere within the system. This extends all the way back to system startup.
During the system’s boot procedures, the system hardware triggers the OS software to load and begin managing the system. To do this, the OS creates a root process, which is responsible for triggering the creation of all other processes required by the OS, including those used during normal system operations. Other processes spawned by the root process may trigger the creation of their own subprocesses, if necessary.
 
Ultimately, these nested operations of process spawning result in a tree-like structure known as the process tree. An abstracted process tree might look something like Figure 1.1-21. Process trees are typically represented with the root process at the top, rather than the bottom.

Figure 1.1-21
Process Tree Terminology
This tree structure gives rise to additional terminology that can be used when referring to processes. Using Figure 1.1-21 as an example:
•	Process 4 is a child process of Process 1, thus making Process 1 the parent process of Process 4.
•	Process 5 and Process 6 are considered sibling processes of one another.
•	Process 3 and Process 7 are considered ancestor processes of Process 8, thus making Process 8 a descendant process of Process 3 and Process 7. Notably, all processes are considered descendant processes of the OS’s root process! These terms are less commonly used to refer to processes which are direct parents or children of each other.
Additional terminology such as grandparent process, grandchild process, great-grandparent process, etc. may also be used, though these are less common. When these terms are used, they usually only apply to processes that have chains of direct parent/child relationships. For example, you are unlikely to hear the term uncle process, except maybe as a bad joke.
Daemon Processes
The root process is responsible for loading every other process necessary for the system to function. Usually, the root process delegates some of these responsibilities by spawning other processes known as daemon processes, or daemons, which manage certain components across the entire OS. For example, a network daemon might handle all network communication for the OS. Daemons usually run in the background and do not require direct interaction with a system user. In fact, daemons generally run continuously, even if no account is logged into the system.
On Windows machines, daemon processes are referred to as services.

9.	Windows | Core Processes
A CDA with deep knowledge about the inner workings of processes can use this knowledge to identify abnormal or potentially malicious processes. This task introduces you to several core processes on Windows systems.
 
The SysAdmin, Audit, Network, and Security (SANS) Institute has produced several publications that can aid in security investigations. Their Hunt Evil poster, which is attached to this task, contains a first page titled Find Evil - Know Normal. Though the entire poster is a fantastic resource for identifying Malicious Cyberspace Activity (MCA) within Windows systems, the Find Evil - Know Normal section in particular describes several processes that are core to the Windows OS, along with their functions, expected parent processes, anticipated start time, and the security implications of these processes.
The information contained within the SANS poster was distilled by the 13Cubed Youtube channel into a Windows Process Genealogy diagram, which is shown in Figure 1.1-22. Review the attachment and the Windows Process Genealogy diagram to learn more about several core Windows processes.

Figure 1.1-22 — Image from 13Cubed’s Windows Process Genealogy diagram, which was adapted from SANS' 2018 Find Evil - Know Normal poster
[See Job Sheet 1-1-1]
Review the current process tree and compare it to the Windows Process Genealogy diagram in
Figure 1.1-22.

10.	Knowledge Check
[See PCTE Knowledge Check]
 
11.	Explorer.exe Process Hierarchy

Figure 1.1-28
The correct answer to the previous question is that the explorer.exe process is an orphaned process that has not been adopted by another process. According to the Hunt Evil poster and the Windows Process Genealogy diagram, explorer.exe is spawned by an instance of userinit.exe, which terminates shortly after, leaving explorer.exe running. This is the exact definition of an orphaned process; the explorer.exe process is an orphaned child process of userinit.exe.
Additionally, the process tree shown in Figure 1.1-28 displays the explorer.exe process on the same level as Windows' root process, System, which indicates that it has not been adopted by any other process on the system.
Within Process Explorer, this can be confirmed by right-clicking explorer.exe, selecting Properties… > Image tab. The parent process of explorer.exe is displayed as <Non-existent Process>, which indicates that the parent process has terminated, and thus, the explorer.exe process is orphaned.

Figure 1.1-29
 
12.	Core Processes | Linux
Linux systems are incredibly diverse and have a staggering array of modular components available to them. Different flavors of Linux OSs may contain the same basic components but implement them in completely different fashions. As such, a Linux Process Genealogy diagram would be nearly impossible to create.
However, there are a few important concepts that one can glean from studying Linux processes.
Daemon Processes in Linux
When inspecting Windows processes, you saw several daemon processes running in the form of services. Daemon processes are usually much more visible within Unix-like OSs. Examples of daemons include the auditd process, which is responsible for writing audit records to the disk. Other examples of daemon processes in a Linux system include the network manager process, which manages network connections, and the display manager process, which manages the entire GUI for the system. Another common daemon process is sshd, which handles incoming Secure Shell (SSH) connections and allows remote users to log in to a terminal on a Linux system.
Daemon processes on Linux systems usually follow the naming convention of adding a d to the end of the process name to indicate that it is a daemon — auditd, sshd, etc.
Init and Systemd
In Linux systems built on top of the System V architecture, the initialization (init) process is the root process that initializes the rest of the OS. As such, it is typically assigned a PID of 1. The init process has been deprecated in favor of the systemd process on most modern Linux distributions, but both accomplish the same task: during the boot process of a Linux OS, the root process is loaded first, and must start all other necessary processes in order to get the system into a desired state.
Runlevels
In legacy systems that still use the init process, runlevels are used to define this desired state. Standard runlevels are defined between 0–6 — each number defines a different state for the system. For example, runlevel 6 is commonly used to reboot the system.
When the system is booted, the init process loads a single runlevel — usually the default level configured by the system — by referencing that runlevel’s associated /etc/rc#.d/ directory, (where # is replaced with the runlevel’s number). This directory contains a list of links to specific scripts located within /etc/init.d/; these scripts are executed sequentially and are used to start or stop various processes required for the system to boot into a specific runlevel. After the machine has been fully booted, the system’s runlevel can be changed on the fly, causing the system to reference the /etc/rc#.d/ directory for the desired runlevel and begin the process anew. Runlevel scripts can be added by a system administrator in order to further configure the system’s functionality.
 
Systemd Targets
Instead of runlevels, systemd loads services that are organized into targets. Though the term target is approximately analogous to the term runlevel, targets and services offer an incredibly large degree of control over the system. A service may be as simple as a one-for-one recreation of a runlevel script, but can include advanced control routines that test for dependencies prior to service execution, such as whether networking is enabled. Runlevels must execute scripts in a linear order, while systemd loads any services in parallel that it can. Additionally, systemd can use sequential targets as a series of checkpoints, which makes sure that the system has entered a predefined state before continuing to load and execute additional targets. Similarly to runlevels, targets can also be changed once the system has booted in order to switch system states.
[See Job Sheet 1-1-2]

13.	Memory Management
During process creation, the kernel allocates memory to a process — this memory contains the stack, heap, data, text, and BSS sections as described earlier. The kernel is responsible for managing the usage of most of this memory during the lifecycle of the process. When a process terminates, the kernel is responsible for deallocating any memory that was used by the process, freeing it up to be reallocated to other processes.
Virtual Memory
Virtual memory is a memory management technique used by modern OSs in order to more effectively manage and secure this key system resource. During process creation, a program and any system libraries it relies on are loaded into the process’s virtual memory. When this process later needs to access or change data held in its virtual memory, it does so via a virtual memory address — the location of the data in its virtual memory. Dedicated hardware known as the Memory Management Unit (MMU) translates these virtual memory addresses into physical memory addresses — actual locations within physical memory such as RAM. To the process, its virtual memory is always present and is always arranged contiguously.
This opens the door for the system and MMU to perform several optimization techniques behind the scenes, without affecting the process’s view of its available memory. These techniques include preventing unnecessary duplication of data by allowing multiple processes to access the same copy of a shared library without interfering with one another. Additionally, the system can perform memory paging as an efficiency mechanism. Memory paging involves assigning inactive portions of a process’s virtual memory to the system’s hard disk instead of to the system’s RAM. Other optimizations are also performed by the system, but the two detailed above are particularly important.
 
Figure 1.1-32 shows how a kernel might translate between a process’s virtual memory and the system’s physical memory, including disk space used for memory paging operations. The black arrows represent the translation steps being performed by the MMU.

Figure 1.1-32 — Image adapted from Wikipedia’s Virtual memory page, CC BY-SA 3.0
Memory Paging
Using a virtual memory scheme, an OS can allocate a sizable chunk of memory to each process running on it. Usually, the amount of memory allocated to each process is a significant portion of the system’s actual physical memory — RAM, in this case. For example, a system may only have 8GB of RAM available, but allocates 4GB of virtual memory to each of 20 running processes. This would obviously far exceed the system’s physical memory capacity.
Thankfully, a process does not often need access to all of its loaded memory at the same time — much of the memory being used at a given time is inactive. Memory paging or memory swapping refers to a technique where inactive virtual memory is saved to a secondary storage device, such as a hard disk, when it is not in use. A unit of memory being saved in this fashion is called a page, hence the name memory paging. When the process needs to reference that memory again, it is loaded back into the system’s RAM.
 
In order to accomplish this, the OS must take over managing memory for a process, which offers the following advantages:
•	Memory can be utilized more efficiently across the entire system
•	System security is increased since applications can usually only access their own virtual memory
•	Applications do not need to contain extra code to manage memory themselves
•	Applications can use more memory than the system hardware actually has available
Unfortunately, secondary storage is usually several hundreds or thousands of times slower to access than RAM. While memory paging certainly can provide increased efficiency and speed across a system, there are instances where the amount of overhead far outweighs the benefits conferred. For example, a very busy system running many processes may not be able to fit all their active memory into RAM, causing the system to perform a large number of page swap operations, which slows the system to a crawl.
Page Files and Swap Files
Windows stores all inactive memory pages inside a page file named pagefile.sys. The default location of this file is located in the root directory of the disk (i.e., C:\pagefile.sys).
Linux instead uses the term swap space to refer to the locations on the disk where inactive memory pages (also known as swap files) are stored. Two separate swap spaces exist. The swap partition is a special location for swapping operations that is reserved directly by the filesystem
— no files other than swap files are allowed to exist within the swap partition. Linux also supports the creation of generic swap files within accessible portions of the filesystem. These generic swap files can be created by a system administrator to allow for more swap space.
Page and swap files are important, since they contain sections of a process’s virtual memory. When performing a forensic or security investigation of a system, these files may serve as a useful evidence source.

14.	File Management
Many processes require the ability to read and write files to a long-term storage medium, such as a hard drive. In order to be used by the system, such storage media must be formatted into a filesystem, which defines a format for organizing, storing, and tracking files. To do this, the filesystem tracks some metadata information about each file, in addition to that file’s actual contents. The tracking of this metadata is done within a record for each file present within the filesystem. Additionally, filesystems maintain a directory to quickly look up the record of each file in the filesystem. A filesystem's directory and list of records exist in a reserved portion of the filesystem. Many filesystem implementations exist; they differ in size, speed, security, functionality, and other factors.
Filesystem Internals
When the kernel receives a request to access a file, it searches through the filesystem’s directory for the appropriately named file, using the directory to determine the location of that file’s associated record in a record list. From the file’s record, the kernel can retrieve metadata information about the file, which includes the physical location of the file’s raw data held within
 
the computer’s hard drive. Figure 1.1-33 shows how the kernel might look for a file in a filesystem, though the exact implementation can differ wildly depending on the filesystem.

Figure 1.1-33
Metadata in Filesystems
Filesystem metadata is stored within a file’s record. This metadata may include the file’s physical location on disk, its size, any associated permissions, and a set of timestamps describing when a file was last modified, accessed, or created. Different filesystem implementations keep track of different metadata information.
Filesystem metadata is a fantastic source of information about the system. Later in this lesson, filesystem metadata is used as an evidence source for a simple investigation.
Virtual Filesystems
A Virtual Filesystem (VFS) is an abstract layer that lies between client applications and the concrete filesystem. A VFS is usually implemented as a kernel module within the OS kernel, and defines a common language that client applications and filesystems can use to communicate, regardless of the specifics of the underlying filesystem. When a client application wants to interact with a filesystem, it uses a system call to ask the kernel for help; the kernel then safely interacts with the appropriate VFS, which performs one last translation step in order to communicate with the concrete filesystem. This offers a key advantage to software developers: rather than writing a ton of extra code to support many different filesystems, the program simply needs to be able to pass file operation instructions to the kernel via a system call.

15.	Types of Filesystems
There are many different filesystems in use across modern and legacy systems. Detailed below are some of the most common filesystems that you are likely to encounter on Windows and Linux OSs.
16.	Windows Filesystems File Allocation Table
File Allocation Table (FAT) is a basic filesystem that uses a specific construct to reference files stored on a disk. FAT comes in several variants, the oldest of which, FAT8, has been around since the 1970s. FAT12, FAT16, and FAT32 are updated versions of the FAT filesystem, and support increasingly larger disk sizes, single file sizes, and longer filenames. FAT12 was used in
 
the very first version of Microsoft Disk Operating System (DOS), and was later replaced with FAT16 and FAT32 in newer Windows OSs. Windows switched away from using the FAT filesystem as a default filesystem with the release of Windows NT 3.1 in 1993.
FAT32 is still used today as the default filesystem for many types of removable media devices, such as flash drives, SD Cards, and external hard disk drives. This is because FAT32 is supported by a wide variety of different systems, which makes it a natural choice for use on removable media storage devices.
Notably, FAT filesystems have no built-in security mechanisms; FAT filesystems do not hold any information about the permissions that should be associated with each file.
New Technology File System
New Technology File System (NTFS) is a journaling filesystem originally developed by Microsoft to replace FAT in Windows NT 3.1. NTFS has undergone several revisions during its lifetime, and provides several enhancements to filesystem performance, efficiency, capacity, resilience, and security. NTFS is still the most common filesystem in use on Windows OSs.
Journaling filesystems can more easily deal with problems caused by unintended interruptions, such as a power outage. A journaling filesystem keeps a journal, a small historical record of operations that are currently being performed within the filesystem. In the event of an unintended interruption to filesystem operations, the journal can be used to help the filesystem recover to a viable state.
Another big reason behind the change from FAT to NTFS is that NTFS natively implements security mechanisms that allow for access controls to be applied directly within the filesystem. NTFS contains two Access Control Lists (ACL), which are associated with each file or directory; the Discretionary Access Control List (DACL) and the System Access Control List (SACL). The DACL is responsible for implementing basic permissions that define which users and/or groups can perform actions, reading, writing, execution, or deletion of a file or folder. The SACL is responsible for determining how the system should audit attempted actions being performed against a file or folder as well as whether those actions succeeded or not. For example, the SACL can be used to log the username of anyone attempting to delete an important file.
Metadata about files and directories within an NTFS are stored in a database known as the Master File Table (MFT), which also serves as the directory for the filesystem. The MFT is an extremely important evidence source that can be utilized to investigate a system that uses NTFS.
Resilient File System
Resilient File System (ReFS) is another filesystem developed by Microsoft, intended to be the next generation Windows filesystem to replace NTFS. According to Microsoft, ReFS was designed to maximize data availability, scale efficiently to large data sets across diverse workloads, and provide data integrity with resiliency to corruption. It seeks to address an expanding set of storage scenarios and establish a foundation for future innovations. ReFS was originally released as part of the Windows Server 2012 OS, but has still not seen widespread adoption.
 
17.	Linux Filesystems
There are many different distributions of the Linux OS that exist, each of which may use a different default filesystem. Several of the most popular filesystems are discussed below.
Extended Filesystem
According to Jim Salter’s Understanding Linux filesystems article, the Extended Filesystem (ext) was created one year after the initial release of the Linux OS. Soon after, ext2 was released and quickly became the default filesystem for use in most Linux distributions. The ext3 filesystem was the first in the ext line to implement journaling capabilities, and ext4 further expanded the functionality provided by ext3. Improvements in ext4 consisted of large filesystem support, improved resistance to fragmentation, higher performance, and improved timestamps. The ext4 filesystem is still the default filesystem in many Linux distributions, such as Debian and Ubuntu.
XFS
XFS is the default filesystem for Red Hat Enterprise Linux — a common Linux distribution. It offers similar features to ext4. Further discussion on this filesystem is not incredibly necessary
— Jim Salter’s Understanding Linux filesystems article states that like ext4, [XFS] should most likely be considered a stopgap along the way towards something better.
ZFS
ZFS is considered a next-generation filesystem because of several fundamental changes in its approach to storage volume management. According to Wikipedia, ZFS was designed with a focus on data integrity, and offers several highly-advanced features that meet this design goal; it provides automatic identification, and (potential) reconstruction of corrupted data via the use of data integrity checking procedures — checksums — across the entire filesystem, as well as native handling of snapshots and backup/replication.
Index Nodes
The Linux kernel supports a large variety of filesystems compared to other OSs. This is because of a construct called the index node (inode) that exists as an abstraction layer within the Linux kernel. Inodes are an integral part of the Linux kernel; all file management behavior within Linux OSs deals directly with these inodes, requiring only that the Linux VFS perform small translation steps between the Linux kernel and the underlying concrete filesystem.
The behaviors made available by inodes include the creation of hard links and symbolic links, which themselves can be used in fairly interesting ways.
Hard Links
When a regular file is created on a Linux machine, the filesystem creates a new record for the file within its record list, and provides a unique ID number back to the Linux kernel. The kernel uses this ID number as the inode ID; the inode ID number is used by the kernel to perform operations against the file located on the filesystem.
Making a hard link to a file creates a new file as normal, but instead of its own inode, the hard link directly references the inode of a different file. Follow the steps below to explore the properties of hard links.
 
[See Job Sheet 1-1-3] Symbolic Links
Symbolic links, also known as symlinks or softlinks, reference a file by that file’s name and location on the filesystem, rather than its inode value. Advantages of symlinks include creating a link to directory locations, and to files or directory locations located on a completely different filesystem. This is in contrast to hard links, which can only reference a file as directory locations do not have their own inode values. Additionally, hard links can only reference files within a single filesystem, since they rely on the filesystem’s internal inode value.
Unfortunately, symlinks do have a drawback; because a symlink does not reference an inode value, moving or deleting the target of the symlink (i.e., the file or directory location that the symlink is referencing) breaks the symlink.
[See Job Sheet 1-1-4]

18.	Knowledge Check
[See PCTE Knowledge Check]

19.	Symlink Chains
The expected output of the cat symlink_3 command is Message #1, as shown in Figure 1.1-55.

Figure 1.1-55
The file symlink_3 references another symlink, symlink_1. The file symlink_1 references the file regular_file_1, which contains the contents Message #1. From symlink_3, the kernel is smart enough to follow the chain of symlinks that was created.
 
This does have a limit — the kernel only follows symlink chains so far. This is illustrated in Figure 1.1-56, which shows symlink_1 being set up as a reference to symlink_2, which itself is a reference to symlink_1.

Figure 1.1-56
It is probably a good thing that the Linux kernel knows how to handle such a weird situation. Otherwise, it would be stuck following the circular symlink references forever.

20.	Network Management
Network devices or network interfaces are specialized hardware peripherals that enable the transmission of data between two or more systems. In modern systems, basic networking interfaces are usually built directly into that system’s hardware. For example, most desktop- grade motherboards contain a single ethernet port, and possibly some other wireless capabilities. A process wishing to send or receive data using a network device must use the kernel as an interface to do so; this allows the kernel’s networking subsystem to manage multiple processes connecting over the same physical networking interface at the same time.
Sockets
A socket is a virtual construct that acts as the endpoint for a communication link on the system. Many sockets can be open on the system at a given time. A client application that is running on the system can request a socket from the kernel, and use system calls to read or write data to the socket.
Socket System Calls
The following system calls (syscalls) are used by an application to request and utilize a socket. Prior to using any of these syscalls, the application must first request a socket from the kernel via a process known as socket instantiation.
•	bind: The application requests the kernel to bind a previously instantiated socket to a network port or to a local file. Binding to a local file is used for communication within the local system only. The bind syscall must be used if the socket intends to listen for incoming connections, and does not need to be used otherwise.
 
•	listen: The application puts the socket into a listening state, meaning that the client application using the socket is actively ready to handle incoming connections. When an incoming connection is received, the application must choose to accept the connection or terminate it.
•	accept: The application accepts an incoming connection to a listening socket. This does not affect the listening socket; a new socket object is created to handle the accepted connection. The accept syscall is mainly used by a listening socket wishing to establish a Transmission Control Protocol (TCP) connection; it is not used for User Datagram Protocol (UDP) communications.
•	connect: The application uses the socket to establish a connection with a different listening socket, which may be on the local system or located on some external network. To connect over a network to a socket present on an external system, the socket must reference the external system’s address, (usually an Internet Protocol [IP] address), and the network port that a listening socket is bound to. The connect syscall is mainly used by a connecting socket wishing to make a TCP connection to a listening socket; it is not used for UDP communications.
•	recv or recvfrom: Short for receive. The application reads data from the socket. The recv syscall can be used as a shortcut by certain applications that have already established a connection with another socket; recvfrom is used otherwise.
•	send or sendto: The application sends data over the socket, which is transmitted to the corresponding socket on the other end of the connection. The send syscall is used as a shortcut by certain applications that have already established a connection; sendto is used otherwise.
•	close: The application closes the established connection. This may be performed by the listening socket or the connecting socket, and is mainly needed to close TCP connections; UDP communications do not maintain the concept of a connection, so there is nothing to close.
Exploring Socket Connections
Follow the steps below to explore creating and connecting to sockets. Perform these steps on the Linux cda-kali-hunt VM since Linux offers several CLIs, which make creating and interacting with sockets easy.
[See Job Sheet 1-1-5] Netstat
During any communication session, each endpoint must keep track of the connection status. Socket information is stored in memory, and can be viewed with a utility like netstat. This socket information includes details about socket addresses and socket state.
NOTE: Some version of the netstat command is present on most OSs, though there may be some differences in available options and output formats.
[See Job Sheet 1-1-6]
The netstat output shows there are two TCP sockets (indicated by the Proto column in the output). It also contains information about the socket addresses — Local Address shows the starting point for a socket, while Foreign Address shows the ending point. In this case, localhost
 
is indicated by the IP address 127.0.0.1. The numbers following the IP addresses are the port numbers that the sockets have been bound to. In your output, one of the sockets should be bound to port 10000; the other socket was assigned an open higher-numbered port by the OS. Lastly, the netstat output shows the State of the connection. Since the sockets are currently communicating with one another, their state shows as Established.
Socket Statistics
The Socket Statistics (ss) command utility is intended as a replacement for netstat, and uses modern syscalls in order to retrieve information about sockets. This means that ss can access more information than is available to other utilities, and is more efficient than utilities like netstat. The netstat utility is still included for legacy support on many systems, though.
[See Job Sheet 1-1-7]
Unfortunately, it would take far too long to dive into the complexities of netstat and ss during this lesson.
Network Interface Information
Recall that all network communication must travel through the system’s network interface hardware. Most OSs have ways to view information about these interfaces.
ifconfig
[See Job Sheet 1-1-8]
The output from the ifconfig command shows three networking interfaces, eth0, eth1, and lo. The lo interface is bound to the IP address 127.0.0.1, and is used to represent localhost. The machine can use either the 127.0.0.1 IP address or the identifier localhost to reference itself in any network connections being made within the system.
Other information can also be seen in the output, such as the number of network packets that have been sent and received via the interface, and any errors or dropped packets that have occurred.
ipconfig
On Windows systems, similar information can be found by running the ipconfig command, as shown in Figure 1.1-66.

Figure 1.1-66
 

21.	Additional Kernel Capabilities
The kernel capabilities described below do not necessitate as much detail as the other capabilities you just reviewed. However, this does not mean they are any less integral to the function of the system. By now, you should recognize the common pattern underlying every portion of the OS
— the OS and the kernel serve to control the function of the system by translating between high- level application code and low-level machine or hardware code. In performing this task, the OS strives to be as efficient, as secure, and as harmless to the system as possible, which may require additional layers of complexity.
Peripheral and I/O Device Management
Modern computers support many different types of peripherals, such as keyboards, mice, speakers, wireless transceivers, and others. These peripherals are generally known as Input/Output devices, since they ultimately provide either an input stream to a system (keyboards, mice, microphones, etc.), or translate a stream of system output into some other form (audio playback, printing, video display, etc.).
Many different protocols exist for communicating with these peripheral devices. For a system to be able to communicate with a particular device, a device driver must be installed on the system. A device driver teaches the kernel how to speak the same language as the device, so to speak. A process wishing to communicate with a peripheral device must use the system’s kernel as an interface between the process and the peripheral device, since the kernel needs to manage usage of the peripheral across multiple different processes simultaneously.
Security Management
Security management is handled by a kernel component known as the security subsystem or security kernel. This portion of the kernel implements basic security procedures within the system. For example, the security kernel can determine if a particular process should be allowed to read, write, or execute a given file based on the permissions applied on the system. The security subsystem is frequently involved in many other operations that the kernel performs.
Kernel Drivers
As stated earlier, the minimum capability required for a kernel to operate is the ability to facilitate the execution of software instructions on the system’s hardware. Though this suffices for simple systems, most modern computers require additional advanced capabilities such as the ones discussed over the past few tasks. In modern OSs, many of these additional components are implemented as kernel modules or kernel drivers. These components do not exist within the core functionality of the kernel, but are instead loaded and unloaded by the core kernel as needed. A good example of this would be a device driver that enables the kernel to communicate with a specific I/O device; if that I/O device is not currently plugged into the system, the driver for it can be unloaded so that the driver code does not consume system resources.
 
CUI
22.	Windows and Linux Architecture
You have just finished reviewing and exploring some abstracted OS architecture concepts. Now, review some specifics of both Windows and Linux OS architecture, as these OSs are used heavily throughout this course. As you dive into certain details of Windows and Linux OS architecture, compare them to the abstracted architecture in Figure 1.1-67.

Figure 1.1-67
Windows Architecture
The OS architecture for Windows NT systems is illustrated in Figure 1.1-68. Windows NT refers to the underlying architecture of the most common Microsoft OSs — everything from 1993’s release of Windows NT 3.1 to modern-day Windows 11 has been built using the Windows NT architecture.

Figure 1.1-68 — Image from Wikipedia’s Architecture of Windows NT page, CC BY-SA 3.0
 
CUI
User Mode
The user mode portion of a Windows OS consists of OS-integral subsystems and several environment subsystems designed to support different application environments. Examples of integral subsystems include fixed system support processes (such as the session manager and login process), service processes (such as the task scheduler and the print spooler service), and certain parts of the security subsystem (for handling security tokens and access management).
User mode subsystems are able to communicate between each other; for example, an application running in the Win32 environment subsystem may need to talk to the security subsystem in order to determine if the application has access to a particular resource. Additionally, user mode subsystems are able to make system calls into kernel mode routines in order to access hardware or higher-privileged functions. These syscalls are sent to the Executive, which runs in kernel mode and contains several services to support user mode subsystems that are attempting to access system resources.
Kernel Mode
Kernel mode has complete access to the system's hardware resources. It is made up of the Executive, the microkernel, any kernel mode drivers, and the Hardware Abstraction Layer (HAL). In Windows, core kernel functions such as multiprocessor synchronization and initializing the system during boot time are contained within the microkernel, which only performs this small set of functions. Additional functionality is implemented into the kernel via the installation and loading of various kernel drivers, several of which come pre-installed with the OS. Lastly, the HAL is used as an interface between the kernel and the actual system hardware. According to Wikipedia, the HAL was designed to hide differences in hardware and provide a consistent platform on which the kernel is run; basically, the HAL translates between the kernel’s low-level software code and the actual system hardware. This architecture offers a key advantage: installing the Windows OS on different CPU architectures would otherwise require major rewrites to the OS, but is accomplished simply by switching out the HAL.
 
CUI
Linux Architecture
Linux’s OS architecture is incredibly similar to both the abstract architecture presented earlier in this lesson, and the Windows OS architecture described above. The Linux architecture is shown below in Figure 1.1-69.

Figure 1.1-69 — Image adapted from M. Tim Jones' Look at Linux, the operating system and universal platform article, retrieved via WayBackMachine
There are clear parallels between Linux and Windows system architecture. For example, Windows’s HAL is analogous to Linux’s arch-dependent code — both of these subsystems perform the last layer of translation between the kernel and the actual system hardware on their respective OSs. In addition, Linux’s kernel interface provides similar functionality as Windows’s Executive services subsystem.
One difference of note is that, in Linux, a fair bit of functionality lies within the drivers and dynamic modules subsystem within the kernel. Though Windows also supports the use of kernel mode drivers, this subsystem is centrally important to the operation of the Linux kernel, and is part of the reason that Linux is so incredibly modular and flexible.
Everything is a File
Unix-like OSs are built with the idea that everything is a file. While this is not true in the literal sense, it speaks to an embedded feature of various Unix-like OSs — many system resources are exposed to the system’s applications via file descriptors. These file descriptors allow other applications to interact with a large variety of different resources in the same way that they would interact with a regular file.
 
CUI
For example, many Unix-like systems contain a file path /proc, which holds information about the state of each process running on the system and their associated system resources. Figure 1.1-70 shows the layout of folders within /proc, which contains a separate subfolder for each process running on the machine. Folders are created based on a process’s PID, and show up in blue in the image. Additionally, Figure 1.1-70 also shows some of the information contained within one of these folders for the process with PID 15060, which is associated with the bash terminal that is shown in the image. Figure 1.1-70 also shows one example of the type of data included in a process’s /proc folder — the cmdline file displays the full command line that was used to start the process — just bash, in this case.

Figure 1.1-70
NOTE: The /proc folder, and other additional directories like /sys, exist within the Linux OS, but not within the underlying filesystem. These directories are actually kept within smaller filesystems that are memory-resident (i.e., the filesystem only exists within RAM while the system is running). This can provide some interesting opportunities for investigation — for example, the code for a running process whose executable has been deleted from the filesystem can be recovered via that process’s /proc entry.
Types of Kernels
Linux and Windows differ because they vary fundamentally in their approaches to OS architecture. Linux uses a monolithic kernel approach — the entire OS was designed to run in kernel mode. In contrast, Windows uses a hybrid kernel approach — the OS was designed such that many larger components, such as the environment subsystems and OS-integral subsystems, run in user mode. A third approach, known as the microkernel approach, is utilized by some
 
CUI
other OSs. The microkernel approach moves as much functionality as possible into user mode execution — except for a very small core kernel. Each approach has distinct advantages and disadvantages, such as faster speeds or more flexibility, though discussing these pros and cons is out of scope for this lesson.

23.	Windows Registry
Though it is not included within the Windows architecture diagram, Windows OSs make use of a construct called the registry to store system and user configuration information. The registry is a hierarchical database that stores information in key:value pairs, persists through system reboots by being saved to the system’s hard disk, and quickly referenced by both user mode and kernel mode processes running on the system. Information contained in the registry can be secured with a standard set of permissions; create, read, update, and delete permissions can be assigned by the owner of a particular registry key in order to limit others' access to the key.
Figure 1.1-71 shows the standard layout of the registry in Windows’s default registry viewing and editing tool, Registry Editor (regedit). The registry is separated into several hives, which contain nested registry keys. Registry keys contain a data type and an associated value.

Figure 1.1-71
Hives and nested registry keys can all be combined together into a registry path. This works similarly to a file path, and can be used to identify a specific registry key. In Figure 1.1-71, the full registry path for the key shown would be HKEY_CURRENT_USER:\\Environment\TEMP. Looking up this key within the registry would return the value
%USERPROFILE%\AppData\Local\Temp.
Registry hives are frequently referenced within the system via a standard set of abbreviations. The most common hives are: HKEY_CURRENT_USER (HKCU), HKEY_LOCAL_MACHINE (HKLM), and HKEY_USERS (HKU).
Registry Investigation
The registry can be a vitally important evidence source during a security investigation. Now that you are familiar with the Windows registry, follow the steps below to identify several useful registry keys.
[See Job Sheet 1-1-9]
 
CUI
You have identified two user profiles on the cda-win-hunt VM: trainee and Administrator. The Administrator account is used for local administrative tasks, and is another common account seen in many Windows installations.
Network Profile Names [See Job Sheet 1-1-10]
24.	Linux Configuration Files
You just finished performing investigative tasks using the Windows registry, which stores system and user configuration information for Windows systems within a central hierarchical database. Unfortunately, Unix-like OSs do not have a similar centralized configuration repository. In keeping with the Unix mantra of everything is a file, configuration information within Unix-like systems are stored as files. These files are known as configuration files, and are used similarly to the Windows registry in order to control how a system or application functions. Configuration files are commonly located within the system’s /etc directory (for system-level configurations), within an application’s installation folder (for application-level configurations), or within a user’s home directory (for user-level configurations). Certain applications or system tasks may involve multiple configuration files that are located in several different locations throughout the system.
Applications running on Windows systems may choose to make use of configuration files rather than, or in addition to, the Windows registry. However, applications running on Unix-like systems generally have no other alternatives.
[See Job Sheet 1-1-11]
Journal files are not truly configuration files — they do not contain information used to determine how the system or an application runs. Instead, the journal files are log files. Log files contain a log of events that occurred in an application or on the system as a whole. Log files are incredibly useful evidence sources to use during investigations. As a CDA trainee, become intimately familiar with many types of common log files that hold security-relevant data.

25.	OS Fundamentals | Conclusion
At this point in the lesson, you have reviewed and explored several key concepts intrinsic to the operation of modern OSs including: OS architecture, kernels, process management, memory management, file management, network management, I/O devices, and other interesting details regarding Windows and Linux OSs, such as the Windows registry and Linux configuration and log files.
As a future CDA, you must learn to apply your technical knowledge within a Cyber Protection Team (CPT) in order to meet mission goals. Ultimately, these mission goals involve investigating and securing networks and systems that are located in an increasingly complex digital landscape. Having a firm grasp on the basic OS concepts presented in this lesson act as a solid foundation to develop the additional skills required of a CDA.
 
CUI
26.	Forensic Principals
Traditional crime scene forensics involves the investigation of evidence sources left behind at the scene of a crime, in order to piece together additional information about that crime. When that crime occurs in relation to a computer system, it requires special investigative techniques that fall under the umbrella of digital forensics. True digital forensics is more frequently found in law enforcement or federal investigations, which ultimately strive to identify, arrest, and prosecute the perpetrator(s) of a crime.
In contrast to law enforcement investigations, the goal of a cyber defense operation is more likely to be the prevention, detection, or mitigation of MCA. When these steps fail, cyber defense operations pivot and perform swift identification and eradication of MCA as well as the implementation of additional measures to prevent, detect, or mitigate similar MCA in the future. To accomplish these goals of protecting or fighting against MCA, a CDA must be prepared to perform investigations of computer systems and networks. It is in this fashion that digital forensics can truly help a CDA. Though the full digital forensics process may not be followed in every mission, an understanding of digital forensics goals and techniques can better equip a CDA to perform investigative tasks in accordance with their mission.
Stages of Digital Forensics
The digital forensics process can be divided into the following stages:
•	Identification of evidence sources
•	Preservation of evidence sources
•	Acquisition of data from evidence sources
•	Analysis and interpretation of the acquired data
•	Presentation of the analysis results
Chain of Custody
One key concept to understand is that prosecution-focused investigations, such as those performed by law enforcement, must go to great lengths to make sure that the evidence being presented is admissible in a court of law. This involves following a strict set of procedures that document all the actions that have been taken involving a particular evidence source during and after its retrieval from a crime scene. These procedures are collectively known as chain of custody and are crucial in order to prove that evidence being presented in court has not been altered or tampered with in any way. Failure to follow chain of custody could entirely invalidate the results of an investigation and subsequent trial, and may lead to the unsuccessful prosecution of an otherwise guilty offender. Though similar guidelines must also be followed for non-digital evidence, certain chain of custody procedures are wholly unique to the field of digital forensics; for example, investigators must use a tool called a write blocker to prevent any modifications to the data contained on an original evidence source such as a hard drive or thumb drive.
 
CUI
During CDA operations, strict adherence to chain of custody procedures is unlikely to be necessary, though this may change during certain missions. However, similar steps may be taken by CDAs in order to maintain the usefulness of evidence sources by protecting them from unrecoverable manipulation or deletion. For example, suspicious files that must be further analyzed by a CDA can be backed up to a separate hard drive prior to their analysis. That way, if the files are accidentally modified or deleted, the backups can be used to recover the original files. In any case, a CDA is likely to spend a large majority of their time in the Analysis stage of the digital forensics process described above.
File Forensics
Much of digital forensics activity is concerned with recovering evidence stored in files within a computer system. In some cases, files are freely available on the filesystem, and an investigator simply needs to locate them and identify whether their contents are relevant to the investigation. In other cases, investigators must attempt to reconstruct deleted files. In both of these cases, investigators may further need to prove that a file is relevant to the investigation; for example, an investigator may need to demonstrate that a picture recovered from the filesystem was taken at a particular time and location.
File Carving
File carving is the process of reconstructing files by scanning the raw bytes of a disk, and attempting to piece together the files without the metadata information normally tracked by the filesystem. File carving may need to be performed during forensic investigations by law enforcement or government agencies, or during data recovery operations. Usually, file carving requires determining the type of filesystem represented by the data on the disk, then using this knowledge to locate and reconstruct the directory and record list held within the filesystem.
In the next few tasks, learn some basic techniques for investigating files on both Windows and Linux systems.

27.	Metadata
Metadata can be simply defined as data about data. Metadata is extremely valuable to an investigation, because it can be used to develop additional inferences about data. For example, knowing the original creation date of a file may allow you to place that file into a timeline of suspicious events that occurred within the system.
The most common types of metadata that are relevant to file forensics include:
•	Creation date and time
•	Program or processes used to create the data
•	Data creator or author
•	Technical standards used
•	Location on a device where the data was created
•	File size
•	Data source
•	Data quality
•	File modifications or programs used to modify
[See Job Sheet 1-1-12]
 
CUI
Certain metadata may be more or less valuable depending on the goals behind the investigation. A true forensics investigation may be extremely concerned with the names of the user accounts who have edited a document, since these can be used to establish an evidence trail that connects a particular user to a specific action.
Exchangeable Image File Format Data
As demonstrated, even simple metadata can be extremely useful during an investigation. The steps below introduce Exchangeable Image File Format (EXIF) data, which is commonly embedded within pictures. Criminal investigations that involve photographs can make good use of EXIF data, since it normally contains information such as the following:
•	Camera make and model used to take the picture
•	Geographical coordinates of where the picture was taken
•	Editing software used to manipulate the picture
•	Image dimensions [See Job Sheet 1-1-13] Linux Stat Command
You used the stat command earlier to explore the difference between hard links and symlinks. All that the stat command does is retrieve basic filesystem metadata about a file.
[See Job Sheet 1-1-14]

28.	Knowledge Check
[See PCTE Knowledge Check]

29.	File Headers
During the last task, you explored metadata present within the contents of two files: a Microsoft Word document and an image file. Some generic metadata, such as the create or modified times of these files, were stored within the filesystem. Other metadata was specific to the filetype in question, such as the GPS coordinates of the image files. This sort of specific metadata was stored within the file header of those files.
A file header is a chosen location, usually found at the beginning of a file, which is used to store metadata specific to a given file format. File headers and file formats are intended to help systems and applications handle any operations that need to be performed against that file format. For example, image files generally contain their resolution within their file header, in order to allow image display applications to read their contents correctly. By looking for specific artifacts unique to a file format, file signatures can be developed, which can be used to identify the format of an unknown file, and provide an investigator clues on how to read or analyze it.
File signatures are an incredibly useful tool for identifying filetypes. A common resource to assist in the identification of various file signatures is Gary Kessler’s File Signatures Table.
 
CUI
Portable Executable Format
The Portable Executable (PE) format is a common file format across many types of executable files on Windows systems. The PE format contains a compiled executable program, along with instructions for how the OS should load that program into memory. The most common file types that make use of the PE format are:
•	Stand-alone executables (.exe)
•	Dynamic-link libraries (.dll)
•	Device driver files (.sys)
•	Control panel items (.cpl)
PE Structure
All PE files begin with the following three sections.
•	DOS Header
○	DOS was the precursor to the Windows OS. Windows continued to rely on certain portions of DOS until the release of Windows XP, so executable code had to play nice with DOS. The DOS header is still present in all PE files today.
•	DOS Stub
○	A stub is a small program or piece of code that is executed by default when an application's execution begins. For Windows executables that cannot be run on DOS systems, an error message This program cannot be run in DOS mode. is printed.
•	PE File Header
○	This contains the actual start of the PE file, which begins telling the OS how to load the rest of the executable code into memory.
Inspecting a PE file inside of a hex editor, these three sections are clearly visible, as shown in
Figure 1.1-94.

Figure 1.1-94
 
CUI
In particular, note that the DOS header starts with the characters MZ, and the PE header starts with the characters PE. The error message within the DOS stub is also clearly visible. If you are able to locate these three items at the start of an unknown file, it is almost certainly a PE file.
Indicators of Compromise
Indicators of Compromise (IOC) are forensic artifacts that serve as evidence that an intrusion has occurred within a host or network. File metadata sometimes contains IOC information that can aid a forensic or security investigation. One common example is the OriginalFilename field present within PE metadata, as shown in Figure 1.1-95. Attackers who distribute PE files as malware payloads may forget to change the OriginalFilename field of the PE file — if the OriginalFilename of the malware is unique enough, it can be used to confidently identify malicious files.

Figure 1.1-95
PE headers can be parsed by several applications, including Windows’s default Right-click > Properties window.

Figure 1.1-96
 
CUI
Other common IOCs used to aid security investigations include various network artifacts, such as IP addresses, domain names, and patterns located in web Uniform Resource Locators (URL).
File Hashes
A file hash is a unique value that is calculated by running a file’s contents through a hashing function. Manipulating even one bit of a file is enough to change the entire resulting hash value, making file hashes incredibly useful for forensic and security investigations. Locating a file hash associated with a known malicious file is strong evidence that MCA has occurred. Hashing functions are also commonly used in many modern cryptographic algorithms.
There are several different hashing functions in current use. Commonly-encountered hashing functions include Message Digest (MD) 5, Secure Hash Algorithm (SHA) 256, SHA512, and SHA1. Figure 1.1-97 shows the Get-FileHash PowerShell cmdlet being used to calculate the SHA256 hashes of two files on a Windows machine. (The sha256sum command can be used to calculate SHA256 file hashes on Linux machines.)
NOTE: The only difference between the files' contents is the addition of a single space, which results in entirely different hash values.

Figure 1.1-97
NOTE: Weaknesses have been discovered in certain hashing functions that mean that hash collisions are possible, though it is extremely unlikely. A hash collision occurs when two files with different contents generate the same hash. Hash collisions have dangerous implications for any cryptographic algorithms that rely on those hashing functions.

30.	Forensic Investigation
Now, navigate through a forensic investigation of some suspicious activity that has occurred on the cda-win-hunt VM. This investigation relies on several OS fundamentals and digital forensics concepts reviewed earlier in the lesson.
[See Job Sheet 1-1-15]

31.	Knowledge Check
[See PCTE Knowledge Check]
 
CUI
Registry Autorun Keys
The Windows registry contains several registry keys that are used by the OS to automatically launch programs upon system startup or user login. These registry keys are known as run keys or autorun keys — frequently shortened to autoruns. Autoruns are frequently used by attackers as a persistence mechanism on systems, as they are an easy method of allowing malware to restart after a system reboot. Autorun entries contain a name and a filepath to the autorun location, which is usually some type of executable file or script. When the OS loads, it simply launches the program referenced by the file path stored in the autorun’s registry value.
Identifying suspicious autorun entries requires some level of experience. Simple tricks that can aid in the identification of suspicious autoruns are to look for exceedingly generic autorun names or autorun file paths in locations often abused by malware, such as temporary folders or a user’s Downloads folder.
[See Job Sheet 1-1-16]

32.	Suspicious Autoruns

Figure 1.1-101
Of the autoruns that appear above, the Updater autorun appears the most suspicious. Recall that the VMware User Process is a range-ism that was discussed at the beginning of this lesson — it can be safely ignored. Windows Defender is the default antivirus application for the Windows OS; additionally, the file path indicated by the WindowsDefender registry key references the legitimate location of Windows Defender files on the machine.
The Updater autorun name is pretty generic, and it references a file located in the trainee user’s Downloads folder. Another thing that makes this autorun pretty suspicious is that the file name, FlashPlayerUpdate.exe, seems to be attempting to masquerade as a legitimate update utility for the Adobe Flash application.
[See Job Sheet 1-1-17]

33.	Knowledge Check
[See PCTE Knowledge Check]
 
CUI
34.	Get-FileHash Results
The file hash of the FlashPlayerUpdate.exe file could be retrieved via the following command:
Get-FileHash FlashPlayerUpdate.exe

Figure 1.1-109
[See Job Sheet 1-1-18]

35.	Knowledge Check
[See PCTE Knowledge Check]

36.	Original File Name
The original file name of FlashPlayerUpdate.exe is NOTEPAD.EXE. This can be found by right- clicking the file and selecting Properties. From there, navigate to the Details tab to retrieve the original file name.

Figure 1.1-110
 
Investigation Conclusion
Someone must have played a prank — the suspicious file uncovered in the Downloads folder seems to be a renamed copy of the harmless Notepad.exe! Whoever did this surely went to great lengths for this prank — a strange FREE CAFE WIFI network was uncovered on the cda-win- hunt VM earlier, along with a suspicious autorun entry that led you to the FlashPlayerUpdate.exe file.
Of course, simply knowing the original file name of a suspicious file is not enough to validate its legitimacy. The file hash, however, is uniquely generated based on the contents of that file — if only there was some way to search for the file hash, you could validate whether it was a legitimate copy of Notepad.
The open-source website VirusTotal.com allows you to do just that! VirusTotal contains a repository of millions of files that have been scanned by dozens of antivirus vendors. There, you can search the hash value of the suspicious file and use it to make the determination that the file is likely safe. Figure 1.1-111 shows that 0 of 68 antivirus vendors have identified the file as malicious. Additionally, VirusTotal shows that the file was distributed by Microsoft, which should give you even more confidence that this file is truly a legitimate copy of Notepad.

Figure 1.1-111

37.	Conclusion
In this lesson, trainees were introduced to the PCTE platform, including a list of range-isms that they are likely to encounter and must ignore for the duration of the Cyber Defense Analyst - Basic, Cyber Defense Analyst - Host, and Cyber Defense Analyst - Network courses. Trainees then reviewed concepts fundamental to the operation of modern OSs. These concepts included OS architecture, the role of the kernel, and details surrounding how the kernel manages processes, memory, files, network interfaces, and peripheral devices. Specifics surrounding Windows and Linux OSs were then discussed, which included an exploration of the Windows registry and several of Linux’s configuration files. Trainees were introduced to the digital forensics process, and learned several basic file forensics techniques including simple filesystem metadata analysis, file header metadata analysis, and file hashing. Finally, trainees completed a short exercise to showcase the skills they had reviewed or developed during the completion of this lesson.
As future CDAs, trainees are tasked with performing difficult technical analysis tasks in an increasingly complex digital landscape. The fundamental OS concepts reviewed in this lesson form a solid foundation upon which additional technical skills can be built. In addition, trainees have started down the path to becoming promising investigators by demonstrating basic competency with simple forensics and investigative tasks.
 
JOB SHEET 1-1-1

OPERATING SYSTEM FUNDAMENTALS
Analyzing Windows Processes
Follow the steps below to acclimate yourself to viewing information about Windows processes using the Windows command line (cmd.exe) and the Sysinternals Process Explorer application.
Workflow
1.	Log in to the cda-win-hunt VM using the following credentials:
Username: trainee
Password: Th1s is 0perational Cyber Training!
2.	Select the Start button. Enter cmd.exe on your keyboard to begin searching; the search bar appears as you begin typing. Select Command Prompt to launch cmd.exe.

Figure 1.1-23
3.	Within the Command Prompt window, the tasklist command can be used to display the current state of all processes running on the system. Enter tasklist into the command prompt, and select Enter to run the command:
C:\Users\trainee>tasklist
4.	Review the output of the tasklist command. You may need to scroll through the Command Prompt window in order to view the full list of output. The output shows the Image Name, PID, Session Name, Session#, and current Memory (Mem) Usage for each process.
 
NOTE: Your tasklist output is different from the output shown in Figure 1.1-24. PIDs of each process may differ, as well as the current memory usage of each process.

Figure 1.1-24
Note the presence of several processes that were indicated in the Windows Process Genealogy
diagram. These processes likely show up near the beginning of the tasklist output.
5.	Close the Command Prompt window.
6.	Open Process Explorer from the desktop. Select Run in the next window that displays.

Figure 1.1-25
 
NOTE: After starting the application, you may additionally need to select the Process Explorer
icon in the taskbar in order to get the application to display.

Figure 1.1-26
7.	Focus on the Process column within Process Explorer, which shows the current process tree on the system. The process tree is displayed as a tabulated list of nested processes. The process tree may update as the system launches or terminates running processes.
 
JOB SHEET 1-1-2

OPERATING SYSTEM FUNDAMENTALS
Analyzing Linux Processes
Follow the steps below to acclimate yourself to viewing information about Linux processes using the bash terminal.
Workflow
1.	Log in to the cda-kali-hunt VM using the following credentials:
Username: trainee
Password: Th1s is 0perational Cyber Training!
2.	Open Terminal Emulator from the system taskbar in the upper left.

Figure 1.1-30
A bash terminal opens.
3.	The ps command is similar to the Windows tasklist command. Run the following command in the terminal. The additional command arguments control the format of the information being displayed.
ps -Hwwfe
 
4.	Review the output of the ps command. You may need to scroll through the terminal using the scrollbar along the right side of Terminal, in order to view the full output.
The output shows the User ID (UID), PID, Parent PID (PPID), and process name of every process running on the system. Figure 1.1-31 shows a sample output from running this command. The output is too long to display in its entirety, so the beginning and end of the output has been stitched together to illustrate several key concepts.

Figure 1.1-31
1.	UID column: Illustrates that users are associated with each process, which is also true within Windows systems. The Unix root user, by default, is allowed to access everything within the system, which includes the ability to execute things within kernel mode in the CPU.
2.	PPID column: Shows the PPID of all the processes on the system. The red arrows at the bottom show the parent/child relationships between several processes involved in the execution of the ps command.
3.	CMD column, bracketed items: Items surrounded by brackets indicate that the processes are executing in kernel mode within the CPU. The very first item in this list is kthreadd — the kernel thread daemon — which is responsible for handling the execution of kernel mode threads. It is no surprise that other kernel threads list kthreadd (PID 2) as their parent process!
4.	CMD column, non-bracketed items: Items not surrounded by brackets indicate processes executing in user mode within the CPU. The highlighted area shows the results of supplying the -H option to the ps command — processes are displayed in a hierarchical relationship, with child processes having their names tabulated underneath their parent process.
 
JOB SHEET 1-1-3


OPERATING SYSTEM FUNDAMENTALS
Hard Links
When a regular file is created on a Linux machine, the filesystem creates a new record for the file within its record list, and provides a unique ID number back to the Linux kernel. The kernel uses this ID number as the inode ID; the inode ID number is used by the kernel to perform operations against the file located on the filesystem.
Making a hard link to a file creates a new file as normal, but instead of its own inode, the hard link directly references the inode of a different file. Follow the steps below to explore the properties of hard links.
Workflow
1.	Log in to the cda-kali-hunt VM using the following credentials:
Username: trainee
Password: Th1s is 0perational Cyber Training!
2.	Open Terminal Emulator from the system taskbar in the upper left.

Figure 1.1-34
A bash terminal opens.

3.	Run the following command in the terminal to change the current directory to one named tmp, which has already been created for you:
cd ~/tmp

Figure 1.1-35
4.	Create a new file containing a simple message by running the following command:
echo "Hello, world." > regular_file
 
5.	Run the ls command to list all files in the current directory, and verify that the file has been created.

Figure 1.1-36
6.	Create a hard link to the newly-created file by running the following command:
ln regular_file hard_link_example
7.	Run the ls command to verify that the hard link has been created.

Figure 1.1-37
8.	The cat command is used to print a file’s content to the terminal. Run the cat command against the hard link:
cat hard_link_example

Figure 1.1-38
As indicated in Figure 1.1-38, the hard link is referencing the file contents of regular_file. Within the filesystem, the hard link to regular_file is represented something like the following:

Figure 1.1-39
 
9.	Run the stat command against regular_file and against hard_link_example:
stat regular_file
stat hard_link_example
Compare the inodes being referenced by each file. Note that both files are referencing the same inode and that both files appear as regular files to the filesystem. Additionally, the system keeps track of the number of references to a particular inode value, which shows up as the number of Links within the stat output.

Figure 1.1-40
10.	Delete the regular_file with the following rm command:
rm ~/tmp/regular_file
11.	Run the ls command to verify that the file was successfully deleted.

Figure 1.1-41
 
12.	Run cat against the hard link file to display its contents:
cat hard_link_example

Figure 1.1-42
Note that the contents that were originally placed within regular_file are still accessible to the hard link.
In essence, the rm command only deleted the filesystem’s directory entry for regular_file. Since the hard_link_example file still exists, the original contents of the deleted regular_file still persist within the filesystem. In fact, as long as there is a single entry anywhere in the directory that references a particular inode, the data associated with that inode remains within the filesystem.
 
JOB SHEET 1-1-4

OPERATING SYSTEM FUNDAMENTALS
NOTE: Steps continued from Job Sheet 1-1-3. Symbolic Links
Symbolic links, also known as symlinks or softlinks, reference a file by that file’s name and location on the filesystem, rather than its inode value. Advantages of symlinks include creating a link to directory locations, and to files or directory locations located on a completely different filesystem. This is in contrast to hard links, which can only reference a file as directory locations do not have their own inode values. Additionally, hard links can only reference files within a single filesystem, since they rely on the filesystem’s internal inode value.
Unfortunately, symlinks do have a drawback; because a symlink does not reference an inode value, moving or deleting the target of the symlink (i.e., the file or directory location that the symlink is referencing) breaks the symlink.
Explore the properties of symlinks by following the steps below. These steps should be performed on the cda-kali-hunt machine after running the cd ~/tmp/ command.
13.	Run the following command to delete the hard link that was created in the previous steps:
rm ~/tmp/hard_link_example
14.	Run the ls command to verify that the file was deleted. No output should display from the ls
command.

Figure 1.1-43
15.	Create a new file containing a simple message by running the following command:
echo "Hello, world." > regular_file
16.	Run the ls command to list all files in the current directory, and verify that the file has been created.

Figure 1.1-44
 
17.	Create a symlink to the newly-created file by running the following command:
ln -s regular_file symlink_example
18.	Run the ls command to list all files in the current directory, and verify that the file has been created.

Figure 1.1-45
Note that the symlink filename is displayed in blue. This is explained in a later step.
19.	Run the stat command against regular_file and against symlink_example:
stat regular_file
stat symlink_example
Compare the inodes being referenced by each file. Note that both files are referencing different inodes. Additionally, note that the file symlink_example shows up as a special file type — a symbolic link rather than a regular file.

Figure 1.1-46
20.	Run the following cat command to display the contents of the symlink file:
cat symlink_example

Figure 1.1-47
Note that the symlink correctly displays the contents of regular_file.
 
The representation of this symlink file within the filesystem currently looks something like the diagram shown below in Figure 1.1-48. The symlink has its own inode, which refers to its own file contents; these file contents contain the path of the file being referenced by the symlink.

Figure 1.1-48
21.	Delete the original file by running the following command:
rm ~/tmp/regular_file
22.	Run the ls command to verify that the file was deleted.

Figure 1.1-49
Note that the symlink filename now displays in red. This highlights that the symlink is currently broken — the file that was previously being referenced by the symlink has been removed from the filesystem.
23.	Attempt to use the cat command to display the contents of the symlink:
cat symlink_example

Figure 1.1-50
An error message displays.
 
24.	Create a new copy of the previously deleted file, this time with a different message. Run the following command:
echo "Catch you later, world!" > regular_file
25.	Run the ls command to verify that the file was created successfully.

Figure 1.1-51
Note that the symlink filename now displays in blue again. This should indicate that the symlink is working properly.
26.	Run the cat command against the symlink to verify that it is working:

Figure 1.1-52
Note that the contents referenced by the symlink file have changed. Instead of displaying the original Hello, world. message, the symlink now references the replaced contents. Deleting or moving the file or directory location being referenced by a symlink does not delete the reference held within the symlink itself.
Additionally, symlinks can be created to map to directories. Symlinks can even reference other symlinks! Both of these are shown in Figure 1.1-53.

Figure 1.1-53
 

JOB SHEET 1-1-5

OPERATING SYSTEM FUNDAMENTALS
Exploring Socket Connections
Follow the steps below to explore creating and connecting to sockets. Perform these steps on the Linux cda-kali-hunt VM since Linux offers several CLIs, which make creating and interacting with sockets easy.
Workflow
1.	Log in to the cda-kali-hunt VM using the following credentials:
Username: trainee
Password: Th1s is 0perational Cyber Training!
2.	Open Terminal Emulator from the system taskbar in the upper left.

Figure 1.1-57
A bash terminal opens.
3.	Within the terminal, run the following command:
nc -v -l -s localhost -p 10000
This command uses the Netcat (nc) utility to create a listening socket. Recall that a socket must include an address and a port number. The address in the command is the local machine — indicated by localhost — and the port number is specified as 10000.
NOTE: According to its Linux man page, the nc utility is used for just about anything under the sun involving TCP or UDP, thus, an in-depth explanation of this utility is out-of-scope for this lesson.

Figure 1.1-58
 
The terminal seems to hang up — this is expected, as the listening socket has taken over the terminal window. Any data received from an incoming connection will be output to the terminal window.
4.	Open a new Terminal Emulator window. Re-organize the windows so both terminals are visible.

Figure 1.1-59
5.	Within the second terminal, use the nc utility to connect to the listening socket that you created. Run the following command to achieve this:
nc localhost 10000
The first terminal contains the listening socket, and outputs that a connection has occurred. The second terminal seems to hang up — again, this is expected, as the socket has now taken over the terminal and uses it to display any data received via the connection.

Figure 1.1-60
 
6.	Data can now be transmitted between the sockets. In either terminal window, enter a friendly message of your choice. Select Enter to send the message to the other socket, and watch as the message is printed to the other terminal window.

Figure 1.1-61
7.	Send a few more messages, if you wish, but do not close either terminal!

Figure 1.1-62
 


OPERATING SYSTEM FUNDAMENTALS
NOTE: Steps continued from Job Sheet 1-1-5. Netstat
During any communication session, each endpoint must keep track of the connection status. Socket information is stored in memory, and can be viewed with a utility like netstat. This socket information includes details about socket addresses and socket state.
NOTE: Some version of the netstat command is present on most OSs, though there may be some differences in available options and output formats.
8.	Open a third Terminal Emulator window. The terminals containing the socket connection can be ignored for now, but do not close them!
9.	Enter the following command to display socket information using the netstat utility:
$ netstat -ntu
An output displays similar to Figure 1.1-63:

Figure 1.1-63
 


OPERATING SYSTEM FUNDAMENTALS
NOTE: Steps continued from Job Sheet 1-1-6. Socket Statistics
The Socket Statistics (ss) command utility is intended as a replacement for netstat, and uses modern syscalls in order to retrieve information about sockets. This means that ss can access more information than is available to other utilities, and is more efficient than utilities like netstat. The netstat utility is still included for legacy support on many systems, though.
10.	Run the following command to display socket information using ss:
ss -ntu
An output displays similar to Figure 1.1-64:

Figure 1.1-64
 


OPERATING SYSTEM FUNDAMENTALS
NOTE: Steps continued from Job Sheet 1-1-7. Network Interface Information
Recall that all network communication must travel through the system’s network interface hardware. Most OSs have ways to view information about these interfaces.
ifconfig
11.	On Unix-like systems, the ifconfig command can be used to view network interface information. Run the following command within a terminal:
ifconfig

Figure 1.1-65
 
JOB SHEET 1-1-9


OPERATING SYSTEM FUNDAMENTALS
Registry Investigation
The registry can be a vitally important evidence source during a security investigation. Now that you are familiar with the Windows registry, follow the steps below to identify several useful registry keys.
Workflow
1.	Log in to the cda-win-hunt VM using the following credentials:
Username: trainee
Password: Th1s is 0perational Cyber Training!
2.	Select the Windows Start menu, enter regedit, and select the regedit application.

Figure 1.1-72
NOTE: If the User Account Control prompt appears, select Yes.
 
The Registry Editor application opens.

Figure 1.1-73
3.	In the Registry Editor application, locate the value of the HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows NT\CurrentVersion\RegisteredOwner registry key.

Figure 1.1-74
This registry key shows Microsoft Valued Customer as the registered owner of the system. This is a default value used by the OS, if no other value was provided during OS installation.
Normally, this key might identify the owner of a particular Windows license.
 
4.	Navigate to the following registry path within the Registry Editor application:
HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows NT\CurrentVersion\ProfileList.

Figure 1.1-75
The additional folders listed under the ProfileList folder represent the different users located on the system. Within the Windows OS, user accounts are assigned a unique Security Identifier (SID) that is used to identify their user profile across the system. The first three SIDs are present on all modern Windows systems; they represent users that are used by the OS to launch certain system services and OS-level tasks. Regular user accounts with no special OS use begin with S- 1-5-21.
5.	Navigate to the SID ending in 1010. Identify the value of the ProfileImagePath key, which identifies the home folder and username of the associated user.

Figure 1.1-76
6.	Navigate to the SID ending in 500 to identify the ProfileImagePath of the other user.

Figure 1.1-77
 
JOB SHEET 1-1-10

OPERATING SYSTEM FUNDAMENTALS
NOTE: Steps continued from Job Sheet 1-1-9. Network Profile Names
7.	Use the registry to identify the names of some of the networks that the machine has connected to. Navigate to the following registry path: HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows NT\CurrentVersion\NetworkList\Profiles.

Figure 1.1-78
As shown in Figure 1.1-78, the Profiles key contains a list of Globally Unique Identifier (GUID) values, which are present throughout the Windows OS. Windows uses GUIDs to refer to unique objects within the system, though GUIDs are not guaranteed to be unique across systems. In this case, each GUID represents a different network profile that this machine has been connected to.
8.	Select each GUID under the Profiles key to identify the associated network names.

Figure 1.1-79
 
One of these network names seems a little suspicious…

Figure 1.1-80
Viewing the list of networks that a computer has connected to can help identify suspicious activity. For example, a user connecting their laptop to an attacker-controlled wireless access point may have had their laptop or their network communications compromised.
 
JOB SHEET 1-1-11

OPERATING SYSTEM FUNDAMENTALS
Follow the steps below to investigate several configuration files on the cda-kali-hunt system.
Workflow
1.	Log in to the cda-kali-hunt VM using the following credentials:
Username: trainee
Password: Th1s is 0perational Cyber Training!
2.	Open Terminal Emulator from the system taskbar in the upper left.

Figure 1.1-81
A bash terminal opens.
3.	Enter the following command to display the contents of the /etc/hostname file:
cat /etc/hostname
This file is used by Linux to identify the name of the system. The system name is cda-kali-hunt, as shown in Figure 1.1-82.

Figure 1.1-82
Though the system hostname is fairly obvious — since you are currently logged into the system
— imagine if you only had access to a hard drive that was removed from a Linux system. Viewing this file would easily enable you to recover the system name!
 
4.	Run the following command to display the contents of the /etc/hosts file, which contains information about IP and domain name resolution for the machine:
cat /etc/hosts

Figure 1.1-83
The /etc/hosts file is used by the machine to shortcut the process of translating domain names into IP addresses, which is normally done via a separate network request. If a domain name and IP address pair is included in the /etc/hosts file, the system can perform the translation itself without performing this additional network request. Malicious actors may add entries to this file in order to redirect traffic or hide their network communication. In Figure 1.1-83, a suspicious entry was added to redirect traffic bound for microsoft.com to an IP address not owned by Microsoft.
 
5.	Some Linux OSs keep track of several journal files, which can serve as a log for various events that occur within the system. These journal files are split into system and user files. System journal files require a higher level of permissions in order to access them. Enter the following command to display the contents of the trainee account’s journal file:
cat /var/log/journal/45627726134a433098b9c96c49beda8c/user-1003.journal
Uh oh! It appears that there is some sort of issue with the journal file!

Figure 1.1-84
Though parts of the journal file are readable, there are weird characters scattered all throughout the output. The ? characters located inside of white diamonds actually represent characters that cannot be properly displayed!
 
6.	In truth, the journal files are stored in a binary format that requires a special tool to view them. Run the following command to correctly view the journal file’s contents:
journalctl --user
This command displays the trainee account’s journal file in a human-readable format. This includes the timestamp of the event, the process that generated the event, and a short description of the event. For example, the second output line in Figure 1.1-85, was generated from the systemd daemon process running into an error starting up another daemon, scdaemon.

Figure 1.1-85
 
JOB SHEET 1-1-12

OPERATING SYSTEM FUNDAMENTALS
Follow the instructions below to investigate metadata related to a suspicious Microsoft Word document found on cda-win-hunt.
Workflow
1.	Log in to the cda-win-hunt VM using the following credentials:
Username: trainee
Password: Th1s is 0perational Cyber Training!
2.	Open File Explorer from the taskbar.

Figure 1.1-86
3.	Navigate to the following file path in File Explorer:
C:\Users\trainee\Documents\
4.	Right-click on Financial Checksheet.doc, and select Properties.
The General tab within the file’s Properties window displays, as shown in Figure 1.1-87. From this tab, the file’s Created, Modified, and Accessed timestamps can be viewed.

Figure 1.1-87
 
Recall that the Windows OS utilizes the NTFS filesystem. NTFS keeps track of four timestamps for each file record stored in the filesystem’s MFT. Three of these are accessible from the Properties tab.
•	File Created: The date on which the file was first created on the filesystem. This timestamp should never change during normal operations, though there are trickier ways to force this time to update.
•	File Accessed: The most recent time the file was accessed. Moving, opening, or reading metadata information about a file is considered an access and causes this value to change. Anti-virus scanners and Windows system processes, which frequently interact with files across the entire system, can also trigger this timestamp to update.
•	File Modified: The most recent time that the file’s contents were modified. For example, if a text file was opened, had a few characters added to it, and was re-saved, the modified timestamp would update.
•	MFT Last Written: The most recent time that the file’s record within the MFT was updated. This timestamp is not included within the standard Windows interface, and necessitates direct inspection of the MFT record, usually via a forensics tool.
4. On the Financial Checksheet.doc Properties window, select the Details tab.
The Details tab displays specific metadata for the selected file. Microsoft Word documents tend to contain plenty of additional metadata, as seen in Figure 1.1-88.

Figure 1.1-88
 
JOB SHEET 1-1-13

OPERATING SYSTEM FUNDAMENTALS
Exchangeable Image File Format Data
Follow the instructions below to investigate EXIF data associated with a few pictures found on the cda-kali-hunt VM.
Workflow
1.	Log in to the cda-kali-hunt VM using the following credentials:
Username: trainee
Password: Th1s is 0perational Cyber Training!
2.	Using the File Browser, open the following directory:
/home/trainee/Documents/stuff/

Figure 1.1-89
There are three pictures in the folder: DCSN0038, DCSN0040, and DCSN0042.
3.	Open Terminal Emulator from the system taskbar in the upper left.

Figure 1.1-90
 
A bash terminal opens.
4.	Run the following command to use the exiftool utility to view the EXIF data associated with the DCSN0038 image:
exiftool ~/Documents/stuff/DSCN0038
The output from exiftool shows various details about the image. You may need to use the scrollbar on the right to see the full output. The beginning of the exiftool output shows information about the file that was gathered from the filesystem. Specific metadata stored within the image’s file contents is not displayed until further down in the output.

Figure 1.1-91
Near the bottom of the exifdata output, information about the GPS coordinates can be found.

Figure 1.1-92
NOTE: Some images may not contain EXIF data. Frequently, this is because the EXIF data was erased, either intentionally or not. For example, social media sites may remove EXIF data included on uploaded pictures. A copy of the original image file is usually required in order to retrieve the most metadata about the image.
 


OPERATING SYSTEM FUNDAMENTALS
NOTE: Steps continued from Job Sheet 1-1-13. Linux Stat Command
You used the stat command earlier to explore the difference between hard links and symlinks. All that the stat command does is retrieve basic filesystem metadata about a file.
5.	Run the following command in the terminal:
stat ~/Documents/stuff/DSCN0040
In addition to the inode value that was viewed earlier, stat also displays timestamps similar to those displayed in NTFS filesystems.

Figure 1.1-93
•	Access: The most recent time the file’s contents were accessed
•	Modify: The most recent time the file’s contents were modified
•	Change: The most recent time the file’s record was changed within the filesystem
•	Birth: The original time the file was created
 


OPERATING SYSTEM FUNDAMENTALS
Workflow
1.	Log in to the cda-win-hunt VM using the following credentials:
Username: trainee
Password: Th1s is 0perational Cyber Training!
 
JOB SHEET 1-1-16

OPERATING SYSTEM FUNDAMENTALS
NOTE: Steps continued from Job Sheet 1-1-15. Registry Autorun Keys
2.	Select the Windows Start menu, enter regedit, and select regedit.

Figure 1.1-98
NOTE: If the User Account Control prompt appears, select Yes. The Registry Editor application opens.

Figure 1.1-99
 
3.	In the Registry Editor, navigate to the following registry path:
HKEY_LOCAL_MACHINE\Software\Microsoft\Windows\CurrentVersion\Run
4.	View the autorun entries present within the above registry path:

Figure 1.1-100
 
JOB SHEET 1-1-17

OPERATING SYSTEM FUNDAMENTALS
Examining the Suspicious PE
1.	Close Registry Editor.
2.	Open File Explorer from the taskbar.

Figure 1.1-102
3.	Navigate to the following file path in File Explorer:
C:\Users\trainee\Downloads\
The suspicious FlashPlayerUpdate.exe file is the only file that exists within the Downloads
folder of the trainee account.

Figure 1.1-103
IMPORTANT NOTE: When interacting with potential malware on a live system, it should always be handled with extreme caution. Best practice dictates that the potentially malicious file should be encrypted for transfer to an analysis VM that has been locked down and is completely isolated from any network connection. Regrettably, this best practice cannot be followed due to constraints present within PCTE. DO NOT CAUSE A SECURITY INCIDENT BY ACCIDENTALLY RUNNING MALICIOUS FILES ON A LIVE SYSTEM.
 
4.	Showcase your data preservation skills! Right-click FlashPlayerUpdate.exe and select Copy.

Figure 1.1-104
Right-click the empty space beneath FlashPlayerUpdate.exe and select Paste.

Figure 1.1-105
A backup copy of the original file is created.

Figure 1.1-106
 
Use the original copy of FlashPlayerUpdate.exe to answer the remaining questions. If you accidentally delete or modify the file, restore it from the backup that you made.
5.	Select the Windows Start menu, enter powershell, and select PowerShell.

Figure 1.1-107
The PowerShell application opens.
6.	Change the current directory to the Downloads folder by running the following command in the PowerShell window.
PS C:\Users\trainee> cd C:\Users\trainee\Downloads
7.	Run the ls command to view the list of files in the Downloads folder.

Figure 1.1-108
8.	Run the Get-FileHash command against the original FlashPlayerUpdate.exe file.
 
JOB SHEET 1-1-18


OPERATING SYSTEM FUNDAMENTALS
Workflow
1.	Close PowerShell.
2.	Using Windows Explorer, navigate to the following folder:
C:\Users\trainee\Downloads
 
OUTLINE SHEET 1-2


SCRIPTING PRIMER
A.	INTRODUCTION
Analysts make use of scripting for many purposes, including automating common tasks, performing hunts, and deploying software. As an analyst, scripts are employed to expand, extend, and rapidly perform duties in the field.
This lesson reviews and expands upon training already received. This lesson requires that you review and edit existing scripts in PowerShell. Additionally, this lesson covers the creation of PowerShell scripts and how to conceptualize them using pseudocode.
Estimated time to complete: 3.0 hours

B.	ENABLING OBJECTIVES
Upon successful completion of this section, you will be able to:

1.2.1	DESCRIBE supported scripting languages
1.2.2	EMPLOY Operating System (OS) specific tools and utilities


C.	TOPIC OUTLINE

•	Overview of scripting
•	Script editing
•	Script creation
•	Adversary usage of scripting


D.	TOOLKIT

PowerShell

PowerShell is a cross-platform task automation solution made up of a command line shell, a scripting language, and a configuration management framework.
 
PowerShell Integrated Scripting Environment (ISE)

PowerShell ISE is a scripting and development environment bundled with some versions of PowerShell. This scripting environment assists with the production of scripts with some helpful features, such as syntax highlighting and autocompletion.
Text Editor

A text editor is used to edit plain text (i.e., no formatting). Some of the more popular programs include Notepad and TextEdit.
Command Line Interface

Command Line Interface (CLI), for the purposes of this lesson, is a generic term for the interface used to execute commands on a system. CLIs include PowerShell terminals, CMD.exe on Windows, Bash, and others.

LESSON 2 — SCRIPTING PRIMER

2.	Overview
Scripting as a Force Multiplier
Analysts use scripts to help extend their capabilities during the execution of missions. Usage of scripts during missions can include automating deployments, performing action execution on ranges of devices at the same time, gathering or parsing information from machines, etc. These capabilities enable you to plan and perform actions that would otherwise be impractical in mission execution time.
Adversary Usage of Scripting
Attackers make use of scripting for various purposes, such as deploying malware, collecting and exfiltrating data, and establishing interactive sessions on compromised systems. Additionally, scripts can be used by attackers to avoid detection to an extent, such as downloading and executing obfuscated scripts without writing them to disk to perform actions on a target machine.
Sensors — agents that detect script execution — are vital for gathering and retaining information, since clearing execution history to hide evidence of Malicious Cyberspace Activity (MCA) is a relatively trivial task for an attacker. Deployment of these sensors as well as analyzing the data provided by them is beyond the scope of this lesson, and is covered in subsequent lessons.
Scripting Languages Used in This Course
This course uses the following scripting languages, which come with their own pros and cons:
•	Windows batch files
•	PowerShell
•	Bash
•	Python
Windows batch file format is usable on all modern versions of Windows. However, the features offered by batch files can be a bit limited and awkward from a modern scripting perspective.
Generally, batch files are used for legacy reasons or for simple tasks, although batch files are fairly common as logon scripts. Simple tasks may be easier to perform or deploy from batch files, however as the complexity of the script grows, the more complicated it can be to create these scripts as batch files. Filenames for batch files end in .bat or .cmd, though the exact execution behavior between these two extensions can differ.
 
PowerShell is a .NET-based, cross-platform scripting solution that has native support for remote execution and is deployed by default on modern versions of Windows, and versions of which are deployable on Unix-like platforms. In addition, its usage can be managed via Group Policy on Windows domains. It contains many features that enable richer scripts, such as full support for object-oriented programming, creation of new cmdlets — small commands or scripts written for PowerShell, which typically return a .NET object for further display or manipulation — for reusable scripting functionality, and many built-in cmdlets for commonly used functions.
PowerShell script filenames end in .ps1, however, other files used in PowerShell can have other extensions.
Bash scripting is typically used on Unix-like systems, such as Linux, MacOS, Berkeley Software Distribution (BSD), etc. In addition, Bash can be deployed to Windows systems through Windows Subsystem for Linux (WSL), Cygwin, or other similar tools. While often seen as limited, this method of scripting is available on any system using the Bash shell, and after years of experience, it is used fairly often for system maintenance. Z Shell (ZSH) and other shells on Unix-like systems often have fairly similar scripting environments that may be mostly compatible with Bash scripts. Shell scripts — which Bash is a subset of — typically have a filename ending in .sh, though this is by convention only, and is not required. Adversaries often choose not to use this file extension.
Python is a programming language often use in scripting. It is cross-platform, and often installed on Unix-like operating systems as well as being deployed on Windows workstations and servers where it is a dependency. Python is well-supported by programming tools that support multiple languages, and has a rich package system available with pip. Python scripts traditionally end in
.py, however, this is not necessary and an adversary can choose not to use this file extension.

3.	Script Editing
Editing scripts can be done with any text editor that saves plain text, such as Notepad, Vi/Vim, Sublime, etc. Some text editors include — or can be configured to use — features that can help make the creation of scripts easier, such as:
•	Syntax Highlighting: Changes the color of text to indicate the category of item that is represented by that text.
•	Autocompletion: Allows the editor to provide probable completions to the text currently being entered (based upon the syntax of the scripting language in use), which can speed up development.
•	Debugging: Allows the pausing of execution of a script or program to view the current state of the environment or manually direct program flow.
•	Script Execution via Hotkey: Executes the script being edited via selecting a button or hotkey, allowing for more rapid execution and development.
 
Throughout this course, the following editors may be used (not exhaustive):
•	Notepad: A simple text editor included in Windows by default; only supports editing.
•	Gedit: The default editor for Gnome; included by default on some Linux distributions. Supports editing and syntax highlighting for any included languages.
•	Nano/Pico: A simple, easy to use command line text editor, commonly available or able to be installed on Unix-like machines. Only supports basic editing, however it may support some syntax highlighting.
•	PowerShell ISE: Integrated into some versions of PowerShell; supports all these features and many more, such as block code execution (executes a highlighted block of code) and help files for PowerShell features.
•	Sublime Text: Included on some machines used during this course; supports syntax highlighting for some scripting languages, and limited autocompletion. Plugins may be available to support other features.
•	Notepad++: An open-source text editor with many features similar to Sublime Text. Supports highlighting for some languages, and supports additional languages via plugins or editing the configuration.
•	Visual Studio Code: This editor behaves as a full-blown Integrated Development Environment (IDE) for many languages — either natively or via plugins. It supports many features to assist development, such as syntax highlighting, autocompletion, debugger support, and many hotkeys and configurations to assist development.
•	Vi/Vim: While this command line text editor has rich configuration support, if used during this course, it is generally used as a basic text editor.
For this lesson, Notepad++ and PowerShell ISE are used to edit or create scripts.

4.	Reviewing and Executing an Existing Script
In this section, review and execute a deployment script.
[See Job Sheet 1-2-1]
 
A breakdown of this script follows: param ($server,$loadkibana,$eventlogs) if ($server -eq $null)
{
while([string]::IsNullOrEmpty($server)){
$server = read-host "Server? Enter just ip or hostname, uses default port"
}
}
if ($loadkibana -eq $null)
{
while([string]::IsNullOrEmpty($loadkibana)){
$loadkibana = read-host "Load Kibana dashboards? Uses same endpoint and default port (y/n)"
}
}
if ($eventlogs -eq $null){ while([string]::IsNullOrEmpty($eventlogs)){
$eventlogs = read-host "Specify event logs (Application, Security, System, etc.) to monitor, separated by commas"
}
}
This section is responsible for receiving inputs via either parameters or prompts. The basic pattern for these parameters involves checking if the value was passed in via param(), then loops until a value is supplied via read-host.
An explanation of some of the concepts used in this code block:
•	-eq is a comparison operator that returns true if the value on the left and right are equal. More comparison operators are covered later in this lesson.
○	More information about these operators can be found here: https://docs.microsoft.com/en- us/powershell/module/microsoft.powershell.core/about/about_comparison_operat ors?view=powershell-5.1
•	param() is used at the top of a script to indicate named parameters that this script accepts. If no parameter is passed in, the value of the variable is $null.
○	More information about this statement can be found here: https://docs.microsoft.com/en- us/powershell/module/microsoft.powershell.core/about/about_scripts?view=powe rshell-5.1
•	while() a while loop continues executing until a specific condition is no longer met (i.e., until the expression being evaluated returns false).
○	More information about this statement can be found here: https://docs.microsoft.com/en- us/powershell/module/microsoft.powershell.core/about/about_while?view=power shell-5.1
 
•	:: is used to execute static methods of .NET classes. In this case, the [string] class has a method named IsNullOrEmpty that checks if a supplied string is null ($null) or a string with no characters.
○	More information about using :: can be found here: https://docs.microsoft.com/en- us/powershell/scripting/samples/using-static-classes-and- methods?view=powershell-5.1
○	More information about [string] methods can be found here: https://docs.microsoft.com/en-us/dotnet/api/system.string?view=net-5.0 (comprehensive and long) and IsNullOrEmpty can be found here: https://docs.microsoft.com/en- us/dotnet/api/system.string.isnullorempty?view=net-5.0
•	read-host is used to read input from the console with an optional prompt.
○	More information about read-host can be found here: https://docs.microsoft.com/en- us/powershell/module/microsoft.powershell.utility/read-host?view=powershell- 5.1
Write-Output ("Generating configuration file sending data to " + $server + ", collecting " +
$eventlogs + " event logs")
Various statements along the way use Write-Output to update the user to the status of the script. These are not called out in the rest of this block.
Write-Output is used to output values to the console. () is used around the value to ensure that it is treated as a single parameter to Write-Output. More information about Write-Output can be found in the MSDN documentation here: https://docs.microsoft.com/en- us/powershell/module/microsoft.powershell.utility/write-output?view=powershell-5.1 .
$config = Get-Content template.yml
This loads the contents of template.yml in order to generate the resulting output later. This file is a Yet Another Markup Language (YAML, also known as YAML Ain't Markup Language) file with portions intended to be replaced with new content by this script. YAML is a simple language intended for use as configuration files — in this case, the configuration file used to deploy this sensor.
Get-Content is used to read the contents of a file as a string. More information about Get- Content can be found here: https://docs.microsoft.com/en- us/powershell/module/microsoft.powershell.management/get-content?view=powershell-5.1
$logconfigsection = ""
foreach($log in $eventlogs -Split ",")
{
$log = $log.Trim() #handle spaces after or before commas
$logconfigsection += " - name: " + $log + "`n" # generate the yml configuration line for this event log type
}
 
This section generates valid YAML sections for use later by looping over $eventlogs after splitting the string on commas to create an array, and uses these values to generate said YAML.
foreach is used to loop through each value supplied by $eventlogs -Split ",". -Split is an operator that splits the string on the left into an array based upon the value on the right (e.g., "foo,bar" - Split "," returns a new array with values "foo" and "bar"). More information about foreach can be found here: https://docs.microsoft.com/en- us/powershell/module/microsoft.powershell.core/about/about_foreach?view=powershell-5.1 and more information about -Split can be found here: https://docs.microsoft.com/en- us/powershell/module/microsoft.powershell.core/about/about_split?view=powershell-5.1.
.Trim() is a method available in the [string] class that returns a new string with any beginning or trailing spaces removed. A character can be supplied if a separate value to be trimmed is needed. More information about [string].Trim() can be found here: https://docs.microsoft.com/en- us/dotnet/api/system.string.trim?view=net-5.0.
"`n” is a string literal that includes an escaped character, in this case newline. There are several other sequences that can be used in string literals, read more about them here: https://docs.microsoft.com/en- us/powershell/module/microsoft.powershell.core/about/about_special_characters?view=powersh ell-5.1.
NOTE: The ` character in the “`n” string literal is the backtick character, which is typically found on the upper-left of the keyboard on the tilde ~ kry.
$logconfigsection is generated by concatenating strings (appending one string to the end of another string). As an example, if System is supplied, the resulting string is:
- name: System<newline>
if ($loadkibana.ToLower() -eq "y")
{
$kibanahost = ' host: "' + $server + ':5601"' # ' used to declare the string rather than " to avoid escaping quotes (`")
}
else
{
$kibanahost = ""
}
$elasticserver = " hosts: [" + $server + ":9200]"
This section generates the Kibana and Elastic Server configurations. The Kibana section depends on whether or not the parameter was supplied to generate that section.
.ToLower() is used to convert the string into a lowercase representation before comparing against y
— an operation that ensures the user can enter either an uppercase or lowercase Y without issue.
#replace templated sections with generated values
$config = $config.Replace("{#event_logs}", $logconfigsection)
$config = $config.Replace("{#kibana_host}", $kibanahost)
$config = $config.Replace("{#elastic_host}", $elasticserver)
 
These statements replace the text within the $config variable with the values stored in
$logconfigsection, $kibanahost, and $elasticserver. The values "{#event_logs}", "{#kibana_host}", and "{#elastic_host}" are present in template.yml, and thus present in $config before this code block is executed. More information about .Replace() can be found here: https://docs.microsoft.com/en-us/dotnet/api/system.string.replace?view=net-5.0.
#write new configuration file
$config | Out-File "winlogbeat.yml"
The newly created output for $config is piped to the Out-File cmdlet, which is used to write to winlogbeat.yml, read more about Out-File here: https://docs.microsoft.com/en- us/powershell/module/microsoft.powershell.utility/out-file?view=powershell-5.1.
$confirm = Read-Host "Configuration file generated and ready to deploy, do you wish to deploy? You must be running as administrator. (y/n)"

if ($confirm.ToLower() -eq "y" -or $confirm.ToLower() -eq "yes")
{
& .\install-service-winlogbeat.ps1
}
else
{
Write-Output "Cancelling deployment, configuration can be reviewed at winlogbeat.yml"
}
This final section determines whether or not to run the actual deployment via a confirmation prompt. & .\install-service-winlogbeat.ps1 launches another script to finish the installation — the default script supplied with Winlogbeat.
Step through the process of deploying this sensor — minus the actual deployment (review the configuration file) — by performing the following steps.
[See Job Sheet 1-2-2]

5.	Knowledge Check
[See PCTE Knowledge Check]

6.	Execution History
Many consoles or terminals store execution history. This can be a useful artifact when performing forensics or for sensors to read. While a malicious actor can often trivially clear the history on a machine, if this log is present, it can still be a useful artifact to be examined.
Bash’s history file is present at <userhome>/.bash_history by default, and PowerShell — since
5.0 — has a default location at
%APPDATA%\Microsoft\Windows\PowerShell\PSReadLine\ConsoleHost_history.txt.
PowerShell’s default location can be changed using the Set-PSReadLineOption cmdlet's - HistorySavePath option, and the location can be displayed using Get-PSReadLineOption.
 
Utilizing History in a Hunt
During the course of their duties, a user - Patti Mcclure - had their credentials stolen. A threat actor used Remote Desktop Protocol (RDP) to connect to the machine, and used PowerShell to perform actions on the machine.
Connect to this machine and determine what actions the threat actor took.
[See Job Sheet 1-2-3]

7.	Knowledge Check
[See PCTE Knowledge Check]

8.	Persistence
According to MITRE, persistence consists of techniques that adversaries use to keep access to systems across restarts, changed credentials, and other interruptions that could cut off their access. In the MITRE Adversarial Tactics, Techniques, and Common Knowledge (ATT&CK) framework, which is used in this course, this has an Identifier (ID) of TA0003. More information about the MITRE ATT&CK framework is provided in later lessons.
The full path to the malicious script that was identified in the command history of the cda-hr-1
host is:
C:\windows\temp\mw1.ps1
Use a text editor to view the contents of this script in order to answer the following question.

9.	Knowledge Check
[See PCTE Knowledge Check]

10.	Knowledge Check
[See PCTE Knowledge Check]

11.	Execution History Conclusion
As the data indicated, the malicious actor was able to gain persistence via a registry run key. In the MITRE ATT&CK framework, this corresponds to T1547.001 — Boot or Logon Autostart Execution: Registry Run Keys / Startup Folder — which consists of multiple readily-detectable methods usable by attackers on Windows.
In addition, the gathering of information by the attacker on cda-hr-1 are examples of Discovery
according to MITRE ATT&CK framework.
 
12.	Script Creation Conceptualizing a Script
When creating or prototyping a new script, there are many methods for determining the best path forward, however these methods generally boil down to:
•	State the problem clearly. This step is vital to ensure that the correct solution is sought out.
•	Determine a big picture solution to the problem.
•	Break the solution down into individual steps that can be performed. If unable to do so, reconsider the solution or research as necessary.
•	Determine how to perform each step in the target language, adjusting overall flow or structure as required based upon feedback here. For steps with many or complex parts, this may require following this process starting back at the beginning for that particular step.
•	Test and deploy the script.
•	Clean up and/or revise as necessary.
One useful tool for articulating the steps necessary to perform a solution — as well as breaking down these steps into discrete sub-steps — is pseudocode. Pseudocode is a plain text description of each step in a structure that resembles code, however is not likely to compile or run in any particular language, such as:
contents = LoadFileAsArray(path) foreach line in contents
{
if line Contains "Password"
{
print(line)
}
}
The above example represents a very simple code segment that loads up a file located at path, reads through each line, and displays any line that contains the word Password in it. This block does not necessarily compile in any specific language, but represents the intent of the code rather than specifying the exact implementation.
The exact syntax of pseudocode is not as important as the clarity and ease of writing and reading. If preferred, it can mimic familiar languages, such as using whitespace to indicate code blocks similar to Python, braces ({}) to indicate code blocks similar to languages like Java, C# or C/C++, or code blocks similar to Basic-style languages.
For example, the above pseudocode block could be represented like so:
contents = LoadFileAsArray(path) foreach line in contents:
if line contains "Password": print line
 
The above block is relatively close to the actual code that might be used, however it simplifies slightly to indicate intent. For a small enough code block, it may be easier to write directly in a target language.
Common Language Features Data Types
Many languages include the following data types or analogs to these data types:
•	String: This data type consists of individual characters, often laid out sequentially in memory (i.e., string of characters, thus the name). String encoding varies by language or platform, with American Standard Code for Information Interchange (ASCII) and Unicode Transformation Format–8-bit (UTF-8) being fairly common — both use eight bits or a single byte to represent a single human-readable character.
•	Integer: This data type corresponds to a numeric, whole number, value. The maximum value that can be stored varies based on the platform and/or language. Many languages also have a long — or similarly named — data type that has a larger possible value; some languages also have a short or byte type that stores smaller values.
•	Array: Also known as lists in a scripting context, this collection type can store multiple values. Exact implementations differ by language. Raw binary data is generally handled as an array — or equivalent per language — of bytes, if available.
•	Float: Floating point number — a number with a decimal point attached. This data type can store both very small and very large numbers due to its ability to move the decimal point — thus a floating point. Some languages have smaller and larger versions with less or more precision — sometimes called single and double.
•	Boolean: Value that represents true or false. Often used to control program flow, such as with if/then statements. Many comparison operators return either true or false.
Variables
Variables are a core feature of most scripting languages. This feature allows the storage of a value, and then overwrites this value with a new value, if needed. For example, the following code leaves the value of number as 2:
number = 1
number = number + 1
Depending on the language, some syntax differences exist with variables, such as requiring the user to specify the type. In addition, depending on the language, the user cannot save a variable of a different type than the existing value. The following code might cause an error message in some scripting or programming languages:
number = 1 number = "one"
In some scripting languages, the language attempts to convert between types automatically, such as between string and integer. If the language attempts to add them, it might cause the language to convert the string to an integer value and parse the string as a numeric value with the resulting value being a number.
 
Input/Output
When creating a script, it is often necessary to take in input or output data. The syntax and methods can vary greatly depending on the scripting language, however these are common input sources and output destinations:
•	Console: The console can often be read from or written to.
•	File: Scripting languages can often read from or write to files.
•	Registry: Scripting languages on Windows may be able to read or write to the registry. This may require the use of external binaries.
•	Databases: Some scripting languages support reading or writing to or from databases, or external binaries may be usable to perform the same operations.
•	Command Line Arguments: Many scripting languages allow command line arguments to be read, and command line arguments can be supplied to other scripts or applications.
•	Network: Scripting languages either natively or through invoking of external code — can allow a script to connect to other machines via networking to send or receive data. This can take the form of Hypertext Transfer Protocol (HTTP) requests, Transmission Control Protocol (TCP) connections, or other lower-level connections. This is useful for downloading software to deploy — legitimate or malicious. Threat actors may also use this functionality to establish remote shells by connecting to a remote machine that issues commands.
These inputs/outputs allow the creation of scripts that can perform many functions. For example, a script might take in command line arguments to create a configuration file with specified parameters, or a script might be written to adjust values in a database depending on input prompts.
Loops/Iteration
Iteration — in some manner — is a common component of scripts. For example, a script can parse through multiple files in a single directory and search each line in the file — a loop inside a loop.
A simple loop might look like this:
for line in lines: print(line)
This loop iterates over multiple items — lines. However, loops can be arbitrary, such as going to a predefined number of iterations:
for x in range(10): print(x)
The above Python code block prints the numbers from 0–9. Note that it is still iterating over a set of values. Some languages support separate conditions for the basic for loop:
for ($x = 0; $x -lt 10; $x++)
{
Write-Output $x
}
 
In this PowerShell code block, the for statement consists of several parts — the three statements separated by semicolons are the initialization block, condition block, and iteration block. The initialization block ($x = 0) is executed first, and is often intended to be used to initialize a variable to be used in the for loop itself. The condition block ($x -lt 10; note that -lt is a less than operator) is an expression that returns a Boolean value (i.e., true or false). The iteration block ($x++; note that $variable++ is used to increment a value by 1 in this example) is executed after each time this for loop is executed, and is intended to be used to change the value of one or more variables being used in the condition block. Notably, in some languages, one or more of these can be empty.
When executed, this PowerShell code block prints the numbers 0–9.
Aside from for loops, many languages support some form of while or do while loops — the syntax and exact behavior changes from language to language — however, the essence of their behavior is that the loop continues while a specified condition is still met. For example:
i = 0
while i < 10: print(i)
i = i + 1
In addition, some languages have a similar construct, known as do…until, which behaves in a somewhat similar way. The syntax of this might resemble:
i = 0 do {
print i i++
} until i = 10
This mimics the behavior of the above for loops. While loops can also branch based upon more complex behavior, such as;
done = False while not done:
# perform work
done = validate() #method that determines if more work exists
This loop continues until done is set to True via validate(). While this example is contrived, a similar pattern may be used in some languages for processing data with an unknown length such as data being received from a remote machine — determine if more data exists, and perform work on a segment of that data.
Most languages support some sort of early exiting for loops — particularly useful in nested loops searching for an index or value. The keyword for this may be something like break. In addition, some languages support skipping to the next iteration via a keyword like continue. This can be useful if the script needs to only operate on values that match specific criteria.
 
Branching Logic
Being able to control the flow of the execution of a script or program is a fundamental feature of any scripting language. This can take the form of if/then statements, switch statements, etc. These statements alter which line is executed next, allowing conditions to alter or direct program flow.
If/then/else statements might resemble the following:
if x:
print("x is true") else:
print("x is false")
In the above, the code block entered depends on what x evaluates to — x can either be a Boolean value, or an expression that evaluates to a Boolean value. Note that if/then statements generally do not require an else block if not needed:
if x:
print("do something with this code path")
Switch statements might resemble the following:
switch(x){ case 1:
print "x is 1" case 2:
print "x is 2" default:
print "unhandled case"
}
In the above pseudocode block, three code paths exist:

•	If x is 1
•	If x is 2
•	Any other value of x

This type of statement can reduce the amount of typing and screen space taken up for repetitive program flow patterns on the same value versus simply using a lot of if/then statements.

13.	Script Creation | Conceptualizing
Parsing log files is a routine duty that any analyst performs often. This can be accomplished in many ways.
Create a script that reads through an authorization log and counts the number of times specific users in a supplied users.txt file appear.
[See Job Sheet 1-2-4]
The next section covers the basics of PowerShell, which is used to create this script at the appropriate step.
 
14.	PowerShell Basics
PowerShell is included with Windows by default, and is a common scripting language for use in the field. This section reviews PowerShell-specific language syntax and features.
Variables
Variables in PowerShell are denoted by a $ in front of the variable name:
$value = "my value"
Variable types are not set in stone — a new value of a different type can be stored:
$value = 1
Common Data Types
Types in PowerShell are specified by encapsulating the type name with brackets (e.g., [string]). PowerShell has many common data types:
•	String
○	String of characters, denoted in a literal by encapsulating the value with either quotation marks ,", or single tick marks, '.
•	Numbers
○	Integer ([int]) supports values from -2,147,483,648 to 2,147,483,647.
○	Short ([short]) supports -32,768 to 32,767. In later PowerShell versions, it is denoted when specifying values by appending s (e.g., $foo = 100s). In versions prior to 6.2 (used in this lesson), it is specified by casting an integer (e.g., ([short]) 100).
○	Long ([long]) supports values from -9,223,372,036,854,775,808 to 9,223,372,036,854,775,807. Denoted as a literal with l (e.g., 100000000l).
○	Decimal ([decimal]) is a base-10 implementation of floating point numbers. Useful for denoting money or other human-derived values where base-10 is desired.
○	Float ([double] or [single]) is a base-2 implementation of floating point numbers. Default is double-precision, operations on floating point values are generally faster than decimal.
•	Collections
○	Strongly typed arrays can be denoted by ending the type of the array with brackets (e.g., [int[]]). New arrays can be declared in a few different ways, one of which is by putting the elements in the array inside parentheses and prepending an @ symbol (e.g., $myarray = @(1, 2) creates an array with values of 1 and 2, while
$myarray = @() creates an empty array). More information about arrays in PowerShell is available here: https://docs.microsoft.com/en- us/powershell/module/microsoft.powershell.core/about/about_arrays?view=power shell-5.1.
○	For storing a value associated with a particular key, PowerShell has hash tables. Hash tables are denoted with an @ symbol followed by braces ({}) (e.g., $table = @{ "foo" = 1, "bar" = 2}) and can be accessed via indexing (e.g., $table["foo"]). More information about hash tables in PowerShell here:
 
https://docs.microsoft.com/en- us/powershell/module/microsoft.powershell.core/about/about_hash_tables?view= powershell-5.1.
○	In addition to these, PowerShell has access to the entirety of collections in the
.NET framework.
•	Boolean
○	Boolean values can be the results of expressions or specified via the constants
$true and $false.
For the number types that only support integer, short, and long, unsigned variants exist for storing only positive values. These are outside of the context of this lesson, but more can be read about them here:
https://docs.microsoft.com/en- us/powershell/module/microsoft.powershell.core/about/about_numeric_literals?view=powershell
-7.1
According to Microsoft’s PowerShell documentation, numeric literals without a type specifier have their type determined using the following logic:
•	If the value can be represented by type [int], that is its type.
•	Otherwise, if the value can be represented by type [long], that is its type.
•	Otherwise, if the value can be represented by type [decimal], that is its type.
•	Otherwise, it is represented by type [double].
Input/Output
Some common input and output methods are covered here:
•	Console
○	Console can be written to in many ways; one is the Write-Output cmdlet.
■	Write-Output can be invoked with a singled unnamed parameter to write output to the console (e.g., Write-Output "Hello World")
○	Console can be read from using the Read-Host cmdlet:
■	$response = Read-Host "Here is my optional prompt"
•	Standard Input/Output
○	While the standard input and output are generally mapped to the console, applications can have their input or output redirected. For example, cmdlets often accept input from other cmdlets (e.g., Get-ChildItem | Sort-Object). The pipe operator (|) is used to indicate redirection of one program’s output to another’s input. More information about pipelines is available here: https://docs.microsoft.com/en- us/powershell/module/microsoft.powershell.core/about/about_pipelines?view=po wershell-5.1.
•	File
○	Files can be read or written to in many different ways, depending on whether or not the file is being read as a string or raw bytes:
 
■	Get-Content can be used to read a file’s contents as string data (e.g., Get- Content 'File.txt'). The output of this directs to the console, unless redirected or stored.
■	Text files can be written by redirecting output with the > operator, such as "Hello World” > File.txt or via Out-File using the -FilePath parameter (e.g., Get-Process | Out-File -FilePath File.txt).
■	Raw binary files can be read and written to using the .NET framework functions for this purpose:
●	[System.IO.File]::ReadAllBytes('file.bin') - full breakdown available here: https://docs.microsoft.com/en- us/dotnet/api/system.io.file.readallbytes?view=net-5.0
●	[System.IO.File]::WriteAllBytes(path, value) - full breakdown available here: https://docs.microsoft.com/en- us/dotnet/api/system.io.file.writeallbytes?view=net-5.0
•	Command Line Arguments
○	Command line arguments can be read in several ways. Arguments can be positional via $args[n] (where n is the index) or named via param ($argumentname, ...) at the top of the file . For example, .\script.ps1 -Foo “test” can be set for $Foo via param ($Foo) — $Foo is set to ”test”.
•	Registry: Covered in subsequent lessons.
 
Loops/Iteration
PowerShell supports several methods of looping or iterating over objects. Some of these are covered here.
ForEach loops can be used to iterate over collections:
ForEach ($Line in $Lines)
{
Write-Output $Line
}
For loops can be used to loop a specific number of times or using conditions:
For ($x = 0; $x -lt 10; $x++)
{
Write-Output $x
}
ForEach — with a range of values — can be used to emulate the above behavior:
ForEach ($x in 0..9)
{
Write-Output $x
}
While loops work as expected, for example:
$x = 0
While ($x -lt 10)
{
Write-Output $x
$x++
}
Do-While loops exist — the difference between the two is that While loops check the condition before executing the code and Do-While loops execute the code block first, and then evaluate whether or not to continue iterating — this means that the code in the Do block executes at least once even if the condition is not met. The syntax is slightly different than the standard while loop:
$x = 0 Do
{
Write-Output $x
$x++
} While ($x -lt 9)
 
Microsoft documentation for these loop statements:
•	for - https://docs.microsoft.com/en- us/powershell/module/microsoft.powershell.core/about/about_for?view=powershell-5.1
•	foreach - https://docs.microsoft.com/en- us/powershell/module/microsoft.powershell.core/about/about_foreach?view=powershell- 5.1
•	while - https://docs.microsoft.com/en- us/powershell/module/microsoft.powershell.core/about/about_while?view=powershell- 5.1
•	do-while - https://docs.microsoft.com/en- us/powershell/module/microsoft.powershell.core/about/about_do?view=powershell-5.1
Branching Logic
PowerShell supports if/then/else statements and switch statements for basic program flow. These statements follow this pattern:
if (condition) {
# perform work
}
else {
# perform different work
}
For example:
if (x -gt y) {
Write-Output "x > y"
}
else {
Write-Output "x !> y"
}
Note that the else code block is optional if not needed for program flow.
PowerShell’s comparison operators (e.g., -gt in this above example) are fairly unique. A selection of these operators are covered later in this lesson.
Switch statements follow this pattern:
switch (value) { condition { Action() }
}
For example:
$value = 3 switch ($value){
1	{ Write-Output "Value is 1" }
2	{ Write-Output "Value is 2" }
3	{ Write-Output "Value is 3" }
}
 
Note that the switch operator can accept an array or list, and compares each value:
$value = @(2, 3) switch ($value){
1	{ Write-Output "Value is 1" }
2	{ Write-Output "Value is 2" }
3	{ Write-Output "Value is 3" }
}
This code block outputs Value is 2 and Value is 3.
More information about these statements can be found in Microsoft’s documentation:
•	if/then/else - https://docs.microsoft.com/en- us/powershell/module/microsoft.powershell.core/about/about_if?view=powershell-5.1
•	switch - https://docs.microsoft.com/en- us/powershell/module/microsoft.powershell.core/about/about_switch?view=powershell- 5.1
Comparison Operators
PowerShell supports many comparison operators, some of the most common ones are shown here:
•	-eq: Equal — Returns True if the left and right values are equal.
•	-ne: Not Equal — Returns True if the left and right values are not equal.
•	-gt: Greater Than — Returns True if the left value is greater than the right value.
•	-ge: Greater Than or Equal — Returns True if the left value is greater than or equal to the right value.
•	-lt: Less Than — Returns True if the left value is less than the right value.
•	-le: Less Than or Equal — Returns True if the left value is less than or equal to the right value.
In addition to these, some string operators are available for fuzzy matching such as the following selection:
•	-like: Like — Returns True if the string on the left matches the wildcard pattern on the right (e.g., "Hello" -like "*ell?” matches because * matches any number of characters and
? matches any character).
•	-notlike: Not Like — Returns True if the string on the left does not match the wildcard pattern on the right.
More details about these and other operators can be found here: https://docs.microsoft.com/en- us/powershell/module/microsoft.powershell.core/about/about_comparison_operators?view=pow ershell-5.1.
[See Job Sheet 1-2-5]
More information about debugging within PowerShell ISE is available here: https://docs.microsoft.com/en-us/powershell/scripting/windows-powershell/ise/how-to-debug- scripts-in-windows-powershell-ise?view=powershell-7.1.
 
For information about debugging from within the terminal, see: https://docs.microsoft.com/en- us/powershell/module/microsoft.powershell.core/about/about_debuggers?view=powershell-5.1.

15.	Script Creation | PowerShell
This segment walks the trainee through converting the pseudocode above into a working script. Questions regarding the output of the execution of this code follow.
This section covers converting the pseudocode (as shown in Figure 1.2-5) into appropriate PowerShell code. Complete the script using your knowledge about PowerShell.
# Load users.txt into a collection
# Ask for or infer path to the log to be analyzed from arguments # Load contents of the auth log into memory
# Split auth log into individual lines
# Read each line, searching for any of the loaded users on that line # For each found user, tick up a counter for that user
# Print users and number of instances
[See Job Sheet 1-2-6]
If successful, proceed to answer questions based on the output of this script.

16.	Knowledge Check
[See PCTE Knowledge Check]

17.	Knowledge Check
[See PCTE Knowledge Check]

18.	Conclusion
In this lesson, you reviewed and executed an existing deployment script, demonstrating the ability of scripts to make deploying software simpler and easier. You conceptualized and then implemented a log parsing script, the process of which enabled you to learn the general process of creating scripts, as well as enabling you to parse and process log files using PowerShell scripts.
In future lessons in this course, these topics are touched upon again, strengthening your usage of scripting to enhance your ability to perform duties in the field.
 


SCRIPTING PRIMER
Workflow
1.	Log in to cda-win-hunt Virtual Machine (VM) using the following credentials:
Username: trainee
Password: Th1s is 0perational Cyber Training!
2.	Open PowerShell ISE from the desktop.
3.	In PowerShell ISE, open the deploy-sensor.ps1 script from the Desktop\winlogbeats folder.

Figure 1.2-1
 
JOB SHEET 1-2-2


SCRIPTING PRIMER
Workflow
1.	Within the terminal window in PowerShell ISE, change to the winlogbeats directory and then run the script.
PS C:\Users\trainee> cd Desktop\winlogbeats
PS C:\Users\trainee\Desktop\winlogbeats> .\deploy-sensor.ps1
2.	Fill in the prompts with following values:
•	Server: cda-onion-m
•	Kibana: n
•	Event Logs: Application,Security,System
•	Deploy: n

Figure 1.2-2
 
3.	Review the resulting configuration file by executing the following command:
PS C:\Users\trainee\Desktop\winlogbeats> Get-Content winlogbeat.yml
Note the variables filled in for the resulting configuration file per the parameters set.

Figure 1.2-3
 


SCRIPTING PRIMER
Workflow
1.	Log in to the cda-hr-1 VM using the following credentials, if prompted:
Username: trainee
Password: Th1s is 0perational Cyber Training!
2.	Locate and open the execution history for Patti Mcclure by browsing in File Explorer to the C:\Users\patti.mcclure\AppData\Roaming\Microsoft\Windows\PowerShell\PSReadline folder and opening ConsoleHost_history.txt.
In this file are several entries. Take notice of any file writes, any scripts being run — ending in
.ps1. Open any scripts executed within in a text editor.
 
JOB SHEET 1-2-4


SCRIPTING PRIMER
Workflow
1.	Log in to the cda-win-hunt VM using the following credentials, if prompted:
Username: trainee
Password: Th1s is 0perational Cyber Training!
2.	Open Notepad++ from the desktop.
3.	Open a new document in Notepad++, and add the steps required to perform these duties:
# Load users.txt into a collection
# Ask for or infer path to the log to be analyzed from arguments # Load contents of the auth log into memory
# Split auth log into individual lines
# Read each line, searching for any of the loaded users on that line # For each found user, tick up a counter for that user
# Print users and number of instances
Note that each segment begins with a #. This is because # is often a comment in many scripting languages, allowing for this to act as comments documenting the resulting script when done.

Figure 1.2-4
 
4.	Convert these steps into pseudocode, if desired:
# Load users.txt into a collection users = LoadUsers(users.txt)

# Ask for or infer path to the log to be analyzed from arguments authpath = args[0]

# Load contents of the auth log into memory # Split auth log into individual lines
foreach line in ReadLines(authpath) {

# Read each line, searching for any of the loaded users on that line foreach user in users{

# For each found user, tick up a counter for that user if line contains user {
users[user].count += 1
}
}
}

# Print users and number of instances foreach user in users {
print user, users[user].count
}
This expresses the intent of the steps in Figure 1.2-4.

Figure 1.2-5
 


SCRIPTING PRIMER
Troubleshooting
PowerShell ISE supports debugging PowerShell scripts, which can be useful during this course. To debug a PowerShell script:
1.	Create a new breakpoint, either using toggle breakpoint from the debug menu, or by selecting
F9.
2.	Save and invoke the script from the ISE terminal.
3.	If the code line that the breakpoint is on is hit, the code stops execution.
From here, variables can be examined to determine if they match expected values. In addition, Step Over (F10), Step Into (F11), and Step Out (F12) can be used to step line by line through the code.
To continue execution normally, remove the breakpoint by toggling it back off, and select Debug
> Run/Continue (F5).
 
JOB SHEET 1-2-6


SCRIPTING PRIMER
Workflow
1.	Log in to the cda-win-hunt VM using the following credentials, if prompted:
Username: trainee
Password: Th1s is 0perational Cyber Training!
2.	Open PowerShell ISE from the desktop, and create a new file.
3.	Construct the script by converting the pseudocode, starting with this line:
# Load users.txt into a collection users = LoadUsers(users.txt)
This can be accomplished via:
# Load users.txt into a collection
$users = (Get-Content "users.txt") -Split "`n"
This uses Get-Content to read the values, and splits on New Line to populate an array into
$users.
NOTE: Get-Content "users.txt" is encapsulated in parentheses so that -Split is not interpreted as an argument for Get-Content.
4.	Validate that $users is being correctly populated by adding the following temporary testing code:
Write-Output $users[0] #only display the first user, validate array is being correctly loaded
Here, $users[0] is indexing on the $users array; pulling the first item — arrays in PowerShell are numbered from 0.
 
5.	Save this script to the desktop as authlog_parse.ps1, and execute it using the built-in terminal:
PS C:\Users\trainee> cd Desktop
PS C:\Users\trainee\Desktop> .\authlog_parse.ps1
NOTE: Use cd .. if reusing the same instance that was used during the review of deploy- sensor.ps1.

Figure 1.2-6
If done correctly, the output should match Figure 1.2-6. Testing iteratively to ensure that pieces are working correctly like this can help ensure that the entire script works as expected when completed.
6.	Remove the temporary testing line, and implement the next line from the pseudocode:
# Ask for or infer path to the log to be analyzed from arguments authpath = args[0]
This is fairly close to the resulting code — add $ in front of authpath and args[0]. The result should resemble:
# Load users.txt into a collection
$users = (Get-Content "users.txt") -Split "`n"

# Ask for or infer path to the log to be analyzed from arguments
$authpath = $args[0]
The output can be tested, if desired, by adding a Write-Output line for this variable as before and passing in an unnamed argument (e.g., .\authlog_parse.ps1 test).
 
7.	Load the specified log file, and create a shell for a foreach loop over the log:
# Load users.txt into a collection
$users = (Get-Content "users.txt") -Split "`n"

# Ask for or infer path to the log to be analyzed from arguments
$authpath = $args[0]

# Load contents of the auth log into memory # Split auth log into individual lines
$log = (Get-Content $authpath) -Split "`n"

# Read each line, searching for any of the loaded users on that line foreach($line in $log)
{

}
8.	To check if the user exists in the supplied users.txt file, a handful of nested loops are required:
if line contains user
Expands into a couple loops:
# Load users.txt into a collection
$users = (Get-Content "users.txt") -Split "`n"

# Ask for or infer path to the log to be analyzed from arguments
$authpath = $args[0]

# Load contents of the auth log into memory # Split auth log into individual lines
$log = (Get-Content $authpath) -Split "`n"

# Read each line, searching for any of the loaded users on that line foreach($line in $log)
{
foreach($user in $users) #iterate over the users
{
# For each found user, tick up a counter for that user if ($line -match $user)
{
# do something
}
}
}
Here, there are nested loops — for each line, check if a user is found.
 
9.	To store the counts, a hash table can be used, which needs to be initialized outside these loops:
$usercounts = @{} #this is the syntax for an empty hash table foreach($user in $users)
{
$usercounts[$user] = 0 #set initial value
}
It is placed as shown:
# Load users.txt into a collection
$users = (Get-Content "users.txt") -Split "`n"

# Ask for or infer path to the log to be analyzed from arguments
$authpath = $args[0]

# Load contents of the auth log into memory # Split auth log into individual lines
$log = (Get-Content $authpath) -Split "`n"

$usercounts = @{} foreach($user in $users)
{
$usercounts[$user] = 0 #set initial value
}

# Read each line, searching for any of the loaded users on that line foreach($line in $log)
{
foreach($user in $users) #iterate over the users
{
# For each found user, tick up a counter for that user if ($line -match $user)
{
# do something
}
}
}
10.	Increase the value stored per user for each match:
if ($line -match $user)
{
$usercounts[$user] += 1
}
Here, the value stored in the hash table is queried, incremented, and set again to the new value.
 
11.	Display the output by adding a Write-Output call at the end of the file:
foreach user in users {
print user, users[user].count
}
It becomes:
# Print users and number of instances Write-Output $usercounts
Write-Output can be used to display collections, such as hash tables. These are formatted as a table for display.
12.	Execute the code from the integrated terminal:
PS C:\Users\trainee\Desktop> .\authlog_parse.ps1 auth.log

Figure 1.2-7
 
OUTLINE SHEET 1-3


NETWORKING REVIEW
A.	INTRODUCTION
Cyberspace Defense Analysts (CDA) and local defenders need to have a detailed understanding of networking at a local network level and at external/enterprise level to effectively hunt and clear threat actors conducting Malicious Cyberspace Activities (MCA), as well as to enable hardening with mission partners. This lesson provides a review of the basics of networking needed for foundational topics. Additional in-depth lessons are found later in this course and in follow-on courses. Often threat actors abuse basic networking protocols to gain accesses to other systems, obfuscate their communications, or redirect normal network traffic through routes that assist them in achieving their goals.
Estimated time to complete: 1.0 hour

B.	ENABLING OBJECTIVES
Upon successful completion of this section, you will be able to:
1.3.1	DISCUSS OSI model layer 2
1.3.2	DISCUSS OSI model layer 3
1.3.3	DESCRIBE subnets
1.3.4	DISCUSS layer 3 routing
1.3.5	DESCRIBE NAT

C.	TOPIC OUTLINE
•	Open Systems Interconnection (OSI) model layers and devices
•	Subnetting overview
•	Routing
•	Network Address Translation (NAT)
 
D.	TOOLKIT

Wireshark

Wireshark is a cross-platform and open-source tool used to analyze packets sent and received across a network interface. It is used by network, software and security personnel for network analysis, troubleshooting, software and communications protocol development, and education.
CMD.exe

CMD is the Windows interactive Command-Line Interface (CLI).
 
INFORMATION SHEET 1-3

LESSON 3 — NETWORKING REVIEW

2.	OSI Model Layers and Devices
The OSI model describes and standardizes the functions and characteristics of communications across various devices, media, and abstractly between applications. Most networking stacks have combined some of these layers in their implementations.
Layer	Protocol Data Unit	Description
Layer 7 — Application	
Data	High-level Application Programming Interfaces (API) (e.g., remote file access, HyperText Transport Protocol [HTTP] and HTTP Secure [HTTPS])

Layer 6 — Presentation	

Data	Translation between networking protocols/services and applications (e.g., encryption/decryption, compression, character encoding like Extensible Markup Language [XML], Secure Sockets Layer [SSL]/Transport Layer Security [TLS], Multipurpose Internet Mail Extensions [MIME])


Layer 5 — Session	

Data	Communication sessions between two nodes (e.g., Remote Procedure Calls [RPC], sockets) — starting, suspending, restarting, and terminating sessions
NOTE: This layer is often incorporated into the Transport Control Protocol/Internet Protocol (TCP/IP) system on most networking stacks, and not a specific separate layer.

Layer 4 — Transport	

Segment/Datagram	Reliable transmission including segmentation/de- segmentation, and error control
This layer is generally implemented as TCP and User Datagram Protocol (UDP), even though UDP is not considered reliable.


Layer 3 — Network	

Packet	Addressing, routing, and traffic control for networks with multiple endpoints and sources
The most common protocol at this layer is IP. Other example protocols include IP Security (IPsec), Internet Control Message Protocol (ICMP), Open Shortest Path First (OSPF), and Routing Information Protocol (RIP).

Layer 2 — Data Link	
Frame	Transmission of data frames between two nodes using a physical medium (e.g., ethernet, Point to Point Protocol (PPP), and the addressing and link control portions of the 802.11 Wireless Fidelity [Wi-Fi] protocols)
Layer 1 — Physical	
Bit	Transmission/reception of raw bits across a physical medium using characteristics such as electrical voltage, radio signals, or optical signals
Table 1.3-1
 
The implementations of the OSI model use encapsulation to wrap the higher-level layers in order to transmit over the physical medium. Figure 1.3-1 represents the way the TCP/IP protocol stack is implemented and is closely related to the OSI model. The concepts of the OSI model are helpful for breaking down how communications should happen, but do not always translate into implementation solutions that are as cleanly defined. The Data Link Layer in the TCP/IP protocol stack handles frame addressing and the transmission/receiving of bits across the medium.

Figure 1.3-1
NOTE: Frame Check Sequence (FCS).
OSI Layer 2 Devices
Devices that operate on layer 2 of the OSI model, or the Data Link Layer in the TCP/IP protocol stack, perform switching operations on frames. Each frame contains addressing associated with a hardware Network Interface Controller (NIC) (Destination Media Access Control [DMAC] address and Source Media Access Control [SMAC] address), an indicator of the next — or encapsulated — protocol, and the data being sent. Most industry standards at this layer also include a preamble and checksum — also called an FCS — to detect errors that may have been introduced during the transmission of the frame.
 
The most common devices that operate at this layer are switches and bridges. Both of these devices include a Media Access Control (MAC) address table, known as a Content Addressable Memory (CAM) table, that tracks which MAC addresses are associated with each port on the switch. Layer 2 devices rely on broadcasts and the SMAC from transmitted frames to build the MAC address table. Bridges operate in the same manner as switches, but are used to connect two or more different transmission medium, linking them together into an aggregate network. A Wireless Access Point (WAP) that has a hard-wired connection as well as wireless is usually operating as a bridge as well — linking the Radio Frequency (RF) medium with the electrical or optical medium other devices may operate on. Figure 1.3-2 shows an example MAC address table with the addresses changed for simplicity. MAC addresses are represented in a variety of formats for human readability by different applications, but are all identical when processed by the Operating System (OS). Some common formats are xx:xx:xx:xx:xx:xx, xxxx.xxxx.xxxx, xxxx:xxxx:xxxx, and xx.xx.xx.xx.xx.xx.

Figure 1.3-2
In this example, there are multiple MAC addresses associated with a single port on the switch. Since a switch normally only connects to a single device, this indicates that port Fa0/24 is connected to another network segment that has at least eight devices — one of which is likely another switch or bridge.
When a frame reaches a switch, if the DMAC in the frame does not match a known MAC address in the CAM table, the switch forwards a copy of the frame to all ports/paths in order to attempt to reach the addressed device. Layer 2 devices separate collision domains. Collision domains can be compared to communications with a two-way radio where only one person can talk at a time. If more than one person — or device on the physical medium — tries to talk at the same time, the communications collide and is lost for all parties. A DMAC of FFFF:FFFF:FFFF is forwarded to all ports/paths by all layer 2 devices, except the port it was received on. This is called the broadcast address at layer 2, but it should not be confused with broadcasts on layer 3.
 
Spanning Tree
Multiple layer 2 devices may be connected together in such a manner that loops could be created. To prevent an overwhelming amount of transmitted frames — also known as a broadcast storm
— most layer 2 devices use a protocol like Spanning Tree Protocol (STP) to identify themselves to the other devices they may be connected to. Layer 2 protocols do not have a Time To Live (TTL) value to indicate when a frame should no longer be forwarded so it is important to ensure there are no loops as a frame could be endlessly forwarded. Through the use of STP, certain ports that are redundant or cause loops may be put into a blocking state to prevent loops and broadcast storms. This blocking port prevents the switch from forwarding out broadcasts on that port. STP has an election process where one device is designated as the Root Bridge. The lowest cost — or shortest path — to the Root Bridge determines if a port is designated as forwarding or blocking. There are additional states like Listening and Learning to allow for faster topology changes and to update MAC address tables. The lowest cost path from a switch’s port to the Root Bridge is designated to be a Root Port. A designated port is a port on a switch with the lowest cost on a specific LAN segment to the root bridge. Each vendor has their own implementation of the standard, which operates slightly differently, but the end result is to create a logical layer 2 topology that prevents switch loops and duplicate frames. STP introduces a large amount of extra traffic on network segments as it has a very frequent update interval to check/verify if any loops still exist so it can make the appropriate changes to both allow traffic and prevent loops.

Figure 1.3-3
 
3.	Knowledge Check
[See PCTE Knowledge Check]

4.	OSI Layer 3 Devices
Devices that operate on layer 3 operate on packets. These packets are routed between networks. Recall that layer 2 devices separate collision domains; each of the colored ovals in Figure 1.3-4 is a separate network — or broadcast domain. Layer 3 devices separate broadcast domains — or networks. Any device that operates on layer 3 is a router. Other devices, like firewalls and proxy servers, operate on multiple layers, but if they separate — or route — between one or more networks, they are also considered a router on layer 3. The most common protocol on layer 3 is IP.

Figure 1.3-4
IP Network Components
IP networks have several components and terms:

•	Network Identifier (ID) (also sometimes known as subnet ID): Portion — # of bits — of an IP address that designates the network on which a host resides — also the base IP address in a network
•	Host ID: Portion — # of bits — of an IP address that designates the host within its network
•	Subnet mask: Mask that specifies which bits are network (binary one) and which bits are host (binary zero)
•	Broadcast address: Last IP address within a network that is reserved to address all hosts in the same network
•	Gateway (also known as next-hop): IP address assigned to a layer 3 device — router — that connects multiple networks together and can route packets between them
•	Default gateway: Layer 3 device used for routing when there is not a more specific gateway specified in the routing table

The vast majority of hosts on the internet still use Internet Protocol version 4 (IPv4) and have not yet migrated to the newer Internet Protocol version 6 (IPv6). Recall from prerequisite training that IPv4 consists of 32-bit addresses and IPv6 consists of 128-bit addresses. IPv6 is intended to
 
resolve IP address exhaustion for publicly-assigned IP addresses in IPv4. A configured gateway is not required for a host to communicate on a local network, but it is required to communicate with other networks. Gateways are used in building the host's local routing table. There is often a default gateway configured to handle routing communications to any network the local host does not have specifically configured in its routing table.
Public and Private IP Addresses
The Internet Assigned Numbers Authority (IANA) is responsible for defining and apportioning IP addresses. IANA apportioned large blocks of IP addresses to Regional Internet Registries (RIR) who then register — or assign — IP address ranges to large organizations. Typically these are registered to very large organizations, governments, and Internet Service Providers (ISP).
The owners of the IP address ranges use them as needed for their networks. Due to the shortage of public IPv4 addresses, IANA reserved several network ranges and designated them for private use, and use Network Address Translation (NAT) — or something similar — to communicate with public addresses. This allows a network to have virtually unlimited private hosts and translate them to a much smaller range of public IP addresses for use on the internet. Table 1.3-2 shows some of the reserved and private IP address blocks.
Address Block	Description
10.0.0.0/8	Private use
100.64.0.0/10	Shared address space (Carrier-Grade NAT)
127.0.0.1/8	Loopback
169.254.0.0/12	Dynamic configuration of IPv4 link local addresses (implemented in Windows using Automatic Private IP Addressing [APIPA])
172.16.0.0/12	Private use
192.0.2.0/24	Documentation (TEST-NET-1) — intended only for use in documentation
192.168.0.0/16	Private use
198.51.100.0/24	Documentation (TEST-NET-2)
203.0.113.0/24	Documentation (TEST-NET-3)
224.0.0.0/4 (224.0.0.0-
239.255.255.255)	Multicast — one source host to multiple destination hosts that are members of that group
240.0.0.0/4	Reserved
::1/128	Loopback
2001:db8::/32	Documentation
fc00::/7	Unique local — similar to IPv4 private use blocks
fe80::/10	Dynamic configuration of IPv6 link local addresses
Table 1.3-2

5.	Windows Networking
This task walks through some of the important Windows networking commands.
[See Job Sheet 1-3-1]
 
Notice the layer 2 MAC addresses assigned to each interface in the Interface list. This is the address that cda-win-hunt uses as the SMAC when communicating on layer 2 — this was also displayed in the results of the ipconfig /all step. This output also shows a layer 3 device — the default gateway (designated by the network 0.0.0.0 and netmask 0.0.0.0) 199.63.64.1.
It is important for analysts and defenders to understand that devices that are connected to multiple networks are likely capable of acting like routers. Just because a host device is not intended to route between networks, if threat actors gain access to that device, they may be able to use it for lateral movement to other networks that do not follow the network design. This abnormal routing may bypass network monitoring sensors.
Address Resolution Protocol (ARP)
Since an IP packet is encapsulated in a frame to transport across a physical medium, hosts need to be able to find a remote host’s layer 2 address — or MAC address — in order to address the frame. ARP is used when a host has a known IP address and needs to know the associated MAC address. An ARP request — who has IP address x? — is sent with a DMAC of FFFF:FFFF:FFFF to ask the remote host to send back its MAC address. When the host that is assigned the IP address receives the ARP request, it sends an ARP reply — I have IP address x.
— only to the original requester.

Figure 1.3-8
The results of an ARP reply are stored in a host's ARP cache — sometimes called a MAC address table or a neighbor cache. Typically after a set time, a cache entry becomes stale — or not current. Each OS handles this differently and has a different default timeout duration.
Windows sends out a new ARP request once a host exceeds the reachable time (~30,000
 
milliseconds times a random factor). Threat actors often view the ARP cache to discover adjacent hosts in order to triage their value and potential for additional access and targeting.
[See Job Sheet 1-3-2]
Since the ARP table is dynamic, the results vary. Most OSs provide a configuration ability to define static ARP mappings, details of which can be found in the help files for the arp command on Windows and Linux.

6.	Dynamic Host Configuration Protocol (DHCP)

Figure 1.3-10
IP addresses can be assigned statically or requested dynamically from a centralized management server. DHCP uses UDP over port 67 for DHCP servers and port 68 for clients. DHCP operations fall into four stages:
•	DHCP server Discovery
•	IP address lease Offer
•	IP address lease Request
•	IP address lease Acknowledgement
Discovery
When a client needs an IP address and is configured to use DHCP to get that address, it first broadcasts a discovery request using the destination IP address 255.255.255.255 and destination MAC address FFFF:FFFF:FFFF. A client may include in its request the last known IP address . If the client is connected to the same network — and that IP address has not been assigned to another host — the server may grant, ignore, or deny the request.
Offer
DHCP servers listen for any broadcast — or unicast — discovery requests on the networks for which they are configured. When the server receives a discovery request, it reserves an IP address out of its pool of addresses and makes a lease offer to the client. The offer is sent unicast, directly to the client’s MAC address and includes the offered IP address as the destination IP address. The DHCP message includes the client's MAC address, the IP address the server is offering, the subnet mask, the lease duration, and the IP address of the DHCP server.
 
Request
Once the client has received the offer from the DHCP server, the client again sends a broadcast packet to actually request the IP address offered. Multiple DHCP servers can operate on the same network, and the client may receive multiple offers. The broadcast includes the specific server the client is requesting the lease from. Since it is a broadcast, the other DHCP servers not handling the request also see the request and place any address reservations they sent back in the pool of available IP addresses. The client request also includes any options — or additional configuration settings — the server may be able to provide. This includes default gateway, Domain Name System (DNS) servers, and Network Time Protocol (NTP) servers.
Acknowledgement
Finally, the DHCP server sends an acknowledgement directly to the client with the full details of the lease and any additional items it is configured to provide.
[See Job Sheet 1-3-3]

7.	Knowledge Check
[See PCTE Knowledge Check]

8.	Subnet Review
This course assumes prerequisite training in the subnetting process and provides a review of the relevant terms and concepts.
IPv4
Classful Networks
The classful networks were defined by the IP address’s leading bits in binary. The leading bits in the Table 1.3-3 correspond with the decimal representation of the start address.
Classless Inter-Domain Routing (CIDR)
Classless networks use the CIDR notation to indicate the number of bits that are used to define the network (bits that are ones).
Class	Leading bits (first octet)	Start address	End address	Default subnet mask	CIDR
notation
Class A	00000000	0.0.0.0	127.255.255.255	255.0.0.0	/8
Class B	10000000	128.0.0.0	191.255.255.255	255.255.0.0	/16
Class C	11000000	192.0.0.0	223.255.255.255	255.255.255.0	/24
Class D (multicast)	11100000	224.0.0.0	239.255.255.255	undefined	undefined
Class E (reserved)	11110000	240.0.0.0	255.255.255.255	undefined	undefined
Table 1.3-3
Table 1.3-4 is a quick reference that converts the CIDR notation to the subnet mask and shows the number of addresses in that network. Each network has a designated broadcast address, which is the last IP address in that range.
 
Many network topologies include point-to-point links between routers. Based on Table 1.3-4, a
/31 or a /30 network are ideal for use in those cases where only two routers are connected to each other. Some network devices cannot use the network ID — the first address in a network — for an actual device. This means that /31 networks are used less often than /30 networks for links between routers in order to maintain maximum compatibility.
CIDR	Subnet mask	Addresses (#)
/0	0.0.0.0	4,294,967,296
/1	128.0.0.0	2,147,483,648
/2	192.0.0.0	1,073,741,824
/3	224.0.0.0	536,870,912
/4	240.0.0.0	268,435,456
/5	248.0.0.0	134,217,728
/6	252.0.0.0	67,108,864
/7	254.0.0.0	33,554,432
/8	255.0.0.0	16,777,216
/9	255.128.0.0	8,388,608
/10	255.192.0.0	4,194,304
/11	255.224.0.0	2,097,152
/12	255.240.0.0	1,048,576
/13	255.248.0.0	524,288
/14	255.252.0.0	262,144
/15	255.254.0.0	131,072
/16	255.255.0.0	65,536
/17	255.255.128.0	32,768
/18	255.255.192.0	16,384
/19	255.255.224.0	8,192
/20	255.255.240.0	4,096
/21	255.255.248.0	2,048
/22	255.255.252.0	1,024
/23	255.255.254.0	512
/24	255.255.255.0	256
/25	255.255.255.128	128
/26	255.255.255.192	64
/27	255.255.255.224	32
/28	255.255.255.240	16
/29	255.255.255.248	8
/30	255.255.255.252	4
/31	255.255.255.254	2
/32	255.255.255.255	1
Table 1.3-4
 
https://www.ietf.org/rfc/rfc3021.txt
Subnets
Each link between routers in Figure 1.3-16 is a separate subnet. Recall from prior training that an IP address cannot exist in multiple networks — or subnets — at the same time. Each network has a defined start address and end address.

Figure 1.3-16
Use Figure 1.3-16 to walk through this brief example. A /30 network (255.255.255.252 subnet mask) has a total of four addresses: a network ID, two assignable IP addresses, and a broadcast address. The /30 means that 30 bits are used for defining the network and 2 bits for the hosts, which is why there are only four available addresses for the hosts. An example of this is the 192.168.50.0/30 network. The range is 192.168.50.0 to 192.168.50.3. The last address is the broadcast address, in this case 192.168.50.3, and the two assignable IP addresses are assigned to the two routers: 192.168.50.1 and 192.168.50.2. Also notice that the router that is assigned 192.168.50.2 has two other networks that it is a part of: 172.16.0.0/16 (255.255.0.0 subnet mask) and 172.17.0.0/16. There are 65,536 addresses in each of those two networks since there are 16 bits used for both the hosts and the network.
Finding a Network ID
Networking hosts and devices use logical operations to determine if a destination host is on the same network or not. Hosts perform a logical AND operation on the IP address and subnet mask.
[See Job Sheet 1-3-4]
 
IPv6
IPv6 addresses use 128-bit addresses — represented in hexadecimal notation. The address space for IPv6 is large enough that the least significant 64 bits are used for hosts on subnets. The most significant 64 bits designate the network — or routing prefix. The most typical implementation of the network portion is 48 bits for the global routing prefix and 16 bits for the subnet ID, but this configuration is up to the registered owner of the routing prefix.

Figure 1.3-20
IPv6 addresses can be shortened in certain circumstances for clarity and readability:

•	One or more leading zeros from a group of hexadecimal digits can be removed (e.g.,
:0042: is shortened to :42:)
•	Consecutive sections of zeros are replaced by two colons (e.g.,
2001:0db8:0000:0000:0000:ff00:0042:8329 is shortened to 2001:0db8::ff00:0042:8329)

With both rules in place, 2001:0db8:0000:0000:0000:ff00:0042:8329 is shortened to
2001:db8::ff00:42:8329.

9.	Knowledge Check
[See PCTE Knowledge Check]
 
10.	NAT/Port Address Translation (PAT) Review
NAT and PAT allow networks to use a limited number of public IP addresses to isolate and translate between a private IP addressing space that is used internally and the public IP addresses needed to communicate with hosts on the internet. NAT is intended as a one-for-one private-to- public address translation (e.g., 192.168.0.1 would always be translated to 200.200.200.1). PAT uses a combination of inside IP address and inside source port to build the translation table. Most devices performing NAT/PAT do not differentiate between the two, unless a specific one-to-one static translation is configured. PAT allows many inside hosts to share the same global address. This course uses Vyatta routers for most of the routing that occurs in the training range. Vyatta routers are similar to other vendor routers, but have a slightly different syntax. Most layer 3 devices have the ability to perform NAT/PAT operations. Figure 1.3-21 shows a rule that is configured to translate any source IP address (0.0.0.0/0) that is routed out interface eth1 to the global address 70.39.165.194. Notice there is no specific reference to PAT. As stated earlier, this is typical and the default for most devices.

Figure 1.3-21
Figure 1.3-22 abstracts the cda-edge-router that is configured to perform address translation.

Figure 1.3-22
The addresses in the Inside local section show the local address and the source port. The router modifies the packets leaving the eth1 interface to use the translated Inside global address and a source port that is available in the router’s pool of IP addresses and port numbers. The router uses the same source port on local and global sides, if available. If that source port is not available, another port number from the pool is used. This can be seen with the translations for the two local addresses that used source port 4292. Both PAT and NAT can be configured with multiple global addresses, and use all the IP addresses and ports in the configured pool to perform translations. If the pool is exhausted, no new connections can be made until older entries time-out, or the translation table is cleared.
 
Identifying the translation that was applied to captured traffic is often non-trivial. Often analysts do not have the correlation between local and global address, especially in complex, tiered- enterprise networks that are managed by several network owners or organizations. When planning for operations in these types of environments, care should be given to ensure that mission partners are aware of any requirements for translations and can support providing that information.

11.	Knowledge Check
[See PCTE Knowledge Check]

12.	Virtual Local Area Network (VLAN)

Figure 1.3-23 — Image from Comnet.net
VLANs have several advantages over traditional network configurations, including: performance, reduced administrative burden, reduced cost, security, and logical workgroups. Multiple traditional networks can exist on a single switch, which reduces the number of devices an administrative group has to manage and purchase. Switches can perform VLAN switching at a higher speed than a router since they do not have to read as much of the frame/packet in order to make a decision about where to send the data. A common use for VLANs is to segregate the management protocols that network devices use for dynamic switching and routing updates from the rest of the user data that traverses a network.
VLANs are a way to separate hosts on the same physical network — layer 2 — into two or more logical networks. Each VLAN has its own broadcast domain and communication between two VLANs require a router that is connected to both networks. Specific ports on a switch can be designated to a specific VLAN, known as VLAN tagging. VLANs are described by multiple standards, primarily based on Institute of Electrical and Electronics Engineers (IEEE) standard 802.1Q. In Figure 1.3-23, only the hosts in the same VLAN can communicate, unless one of the routers (NW9AP or NW9CL) sends the traffic to the other network. In this case, the voice devices are separated from the normal computers. There is not likely very many reasons for the voice devices to have direct communications with other host computers, so this makes it easier to identify anomalous connections, if network monitoring is appropriately positioned.

13.	Packet Analysis of Layer 2/3
Use the provided example PCAP and analyze the layer 2 and layer 3 protocols.
[See Job Sheet 1-3-5
 
14.	Knowledge Check
[See PCTE Knowledge Check]

15.	Layer 2 Protocols [See Job Sheet 1-3-6]
This is a partial output of the CDP section. CDP is sent to a vendor reserved multicast DMAC, 01:00:0C:CC:CC:CC. Notice there is a very large amount of data that this switch is advertising to its neighbors. Some of the interesting data is:
•	Device ID: CCNP-LAB-S2.webernetz.net
•	IP address: 192.168.121.20
•	CDP sent out port GigabitEthernet0/2
•	C2950 Cisco switch
•	Cisco Internetwork Operating System (IOS) Version 12.1(22)EA14, RELEASE SOFTWARE (fc1)
Additional lessons cover switching, routing, and other network protocols more thoroughly. Network monitoring solutions can monitor networking protocols like CDP and alert if new devices are captured, or provide a baseline of the normal traffic on each VLAN. These tools make identifying anomalies — such as spikes or drops — in traffic easier to identify and start the initial investigation into what changed.

16.	Knowledge Check
[See PCTE Knowledge Check]

17.	Conclusion
Understanding networking basics and how different protocols operate with each other is a skill that is built upon during successive lessons. VLANs are a valuable tool to segregate devices and hosts that do not need to normally communicate with each other.
In this lesson, you analyzed broadcast traffic, such as ARP, DHCP, CDP, and STP. VLANs can help limit the hosts that can see that broadcast traffic. A good practice is to place network infrastructure devices, network management protocols or hosts, and other high-value systems in separate VLANs away from other network traffic. If an attacker manages to gain access to a user’s computer, imagine all the additional targeting data they could use with something like CDP. With the model and version number of a Cisco switch, it is easy to search for publicly- released exploits to take advantage of that.
Networking devices are sometimes afterthoughts for administrators conducting patch management. Layer 2 and 3 devices are harder to update as it is much harder to schedule downtime for critical components of a network. Special attention should be given to these devices since they are the keepers of the data, so to speak. They manipulate every frame and packet that traverses a network, so any compromise of them is much more serious.
 
JOB SHEET 1-3-1


NETWORKING REVIEW
Workflow
1.	Log in to the cda-win-hunt Virtual Machine (VM) using the following credentials:
Username: trainee
Password: Th1s is 0perational Cyber Training!
2.	From the Start menu, enter cmd.exe. Right-click Command Prompt, and select Run as administrator > Yes on the User Account Control window.
3.	Run the ipconfig /all command to view the IP configuration for cda-win-hunt.
C:\Windows\system32>ipconfig /all

Figure 1.3-5
Notice that this host has two interfaces configured — each of which is on a separate network — and that there is a default gateway configured. Recall that the definition of a layer 3 device is one that is on multiple networks and can forward packets from one network to another. Windows 10, as well as the majority of Linux distributions, has the capability to be used as a router, but this is disabled by default as the OS is not designed with that as a core capability.
 
NOTE: The 10.10.0.0/16 network is for range administration and is not in scope for this course. Unless specifically instructed, trainees should not attempt to perform any actions or change any configurations on the 10.10.0.0/16 network. The output of commands that include the 10.10.0.0/16 network may differ from static screenshots when run by trainees during exercises.
4.	Query the Windows registry and examine the IPEnableRouter key: C:\Windows\system32>reg query HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\Tcpip\Parameters

Figure 1.3-6
If this registry key had a value of 1 and the Routing and Remote Access Windows service was running, this host would be considered a layer 3 device since it is able to forward packets from one network to another. Later lessons extensively cover the registry and routing.
5.	Enter the following command to display the routing table:
C:\Windows\system32>route print

Figure 1.3-7
 


NETWORKING REVIEW
NOTE: Steps continued from Job Sheet 1-3-1.
6.	Run the arp command to view the ARP table:
C:\Windows\system32>arp -a

Figure 1.3-9
 


NETWORKING REVIEW
Workflow
1.	Log in to the cda-win-hunt VM using the following credentials:
Username: trainee
Password: Th1s is 0perational Cyber Training!
2.	Open M1L3-dhcp-pcap.pcap from the desktop in Wireshark.

Figure 1.3-11
Packet capture source: https://gitlab.com/wireshark/wireshark/-
/wikis/uploads/  moin_import  /attachments/SampleCaptures/dhcp.pcap
The Wireshark Foundation maintains a GitLab page with publicly available sample packet captures for many different protocols that can be used to familiarize and analyze protocols that may not exist on a local network. A URL is listed in the Additional Resources section.
https://gitlab.com/wireshark/wireshark/-/wikis/SampleCaptures
 
3.	Examine the DHCP Discover packet and expand the Dynamic Host Configuration Protocol
section in the middle frame:

Figure 1.3-12
Notice the Layer 2 — Ethernet II — destination address is the broadcast address ff:ff:ff:ff:ff:ff, and that the client does not have the previous IP address that it is requesting — as indicated by 0.0.0.0.
4.	Select the DHCP Offer packet and scroll down to the Dynamic Host Configuration Protocol
section:

Figure 1.3-13
 
Notice the offer includes the offered IP address (192.168.0.10), the subnet mask (255.255.255.0), the lease time (3600 seconds), and the DHCP server’s IP address (192.168.0.1).
5.	Select the DHCP Request packet:

Figure 1.3-14
Notice that this packet again is a broadcast packet. The DHCP server the client is requesting to use is shown in the option for DHCP Server Identifier as well as the requested client IP address. Additionally, the client requested the subnet mask, router (default gateway), DNS server, and NTP server.
6.	Select the DHCP Acknowledgment (ACK) packet:

Figure 1.3-15
 
Notice this final packet did not return any additional configuration items, and only acknowledged the request which finalized the lease. The lack of additional options in the response indicates the DHCP server does not have the data to provide to the client.
 
JOB SHEET 1-3-4


NETWORKING REVIEW
Workflow
1.	Log in to the cda-kali-hunt VM using the following credentials:
Username: trainee
Password: Th1s is 0perational Cyber Training!
2.	From the toolbar on the top, open Terminal Emulator.
3.	Enter the following command and take note of the IP configuration for eth1:
$ ifconfig

Figure 1.3-17
The binary representations of the IP address and subnet mask are in the following code block. The result of a logical AND of the two numbers is shown on line four.
NOTE: 199.63.64.0 is the network ID for this subnet.
11111111.11111111.11111111.00000000 (255.255.255.0)
11000111.00111111.01000000.00110011 (199.63.64.51)
===================================	LOGICAL AND 11000111.00111111.01000000.00000000 (199.63.64.0)
Some Linux distributions come with the netmask command, which can be run from the command line and show the result in decimal.
 
4.	Run the following command to see the network ID and CIDR for this IP address:
$ netmask 199.63.64.51/255.255.255.0

Figure 1.3-18
5.	Run the following command below to see the range of IP address in the network
$ netmask -r 199.63.64.51/24

Figure 1.3-19
 
JOB SHEET 1-3-5


NETWORKING REVIEW
Workflow
1.	Log in to the cda-win-hunt VM using the following credentials:
Username: trainee
Password: Th1s is 0perational Cyber Training!
2.	Open M1L3-PCAP.pcap from the desktop:

Figure 1.3-24
 
3.	Select Protocol Hierarchy from the Statistics menu:

Figure 1.3-25
Notice that almost 90% of the packets in this capture have VLAN headers. If this network was known to tag all traffic with a VLAN ID, any packets that did not have a VLAN header would need to be analyzed and identified as malicious or non-malicious. In this case, there is a mix of VLAN and non-VLAN traffic so the results are expected.
4.	Close the Statistics window.
5.	Run the following filter in the Display Filter section of Wireshark to filter VLAN packets:
vlan
 
6.	Select packet number 1 and expand the Ethernet II and 802.1Q protocol headers:

Figure 1.3-26
Notice this packet is tagged for VLAN ID 121 and contains an IPv6 packet.
7.	Run the following filter to remove VLAN ID 121:
vlan && !vlan.id==121

Figure 1.3-27
 
This filter displays all VLAN packets AND that are NOT in VLAN ID 121. As can be seen, this packet is tagged for VLAN ID 80. A similar workflow can be used to either show or not show a specific VLAN. The status bar shows that 2,058 packets VLAN packets were NOT tagged for VLAN ID 121.
 
JOB SHEET 1-3-6

NETWORKING REVIEW
NOTE: Steps continued from Job Sheet 1-3-5.
8.	Select X to clear the display filter and run the following filter to show STP packets:
stp
9.	Select packet number 2 and expand the Ethernet II and Spanning Tree Protocol sections, if not already expanded.

Figure 1.3-28
This packet was sent to all the switches listening on the Per VLAN Spanning Tree+ (PVST+) MAC address — a Cisco proprietary protocol extension that allows switches to have multiple spanning trees that take into account VLANs. Notice in the STP section, this switch advertises its current status (designated), it is forwarding frames, learning new MAC addresses, and switching paths. The Root Bridge is also identified by the MAC address for this VLAN (VLAN ID 121).
 
10.	Run the following display filter to analyze ARP packets and select packet number 2553:
arp

Figure 1.3-29
Notice that this ARP request is sent to the layer 2 broadcast address FF:FF:FF:FF:FF:FF and includes the sender’s IP address (192.168.121.253) and the target’s IP address (192.168.121.2), but the target MAC address is blank (all zeros).
 
11.	Select packet number 2554:

Figure 1.3-30
This is the ARP response to the previous step’s request. Notice that all the relevant fields now have addresses in them so these two hosts can now communicate unicast instead of broadcast. Also, note that the ethernet addresses are both unicast and not broadcast like the request.
Another protocol that occurs on layer 2 is the Cisco Discovery Protocol (CDP). CDP is used by Cisco switches — and supported by many non-Cisco switches — to discover and advertise themselves to nearby switches and routers.
12.	Run the following filter to display CDP packets:
cdp
 
13.	Select packet number 133 and expand the Cisco Discovery Protocol section.

Figure 1.3-31
 
APPENDIX A REFERENCES

The following resources were referenced during the creation of this lesson.
•	Gabreiele Tolomei’s blog post, In-Memory Layout of a Process — https://gabrieletolomei.wordpress.com/miscellanea/operating-systems/in-memory-layout/
•	Wikipedia, Protection ring — https://en.wikipedia.org/wiki/Protection_ring
•	Wikipedia, Virtual memory — https://en.wikipedia.org/wiki/Virtual_memory
•	Wikipedia, Network socket — https://en.wikipedia.org/wiki/Network_socket
•	Wikipedia, Daemon (computing) — https://en.wikipedia.org/wiki/Daemon_(computing)
•	M. Tim Jones, Look at Linux, the operating system and universal platform, retrieved via WayBackMachine— https://web.archive.org/web/20210303002650/http://www.ibm.com/developerworks/libra ry/l-linuxuniversal/
•	Rob Lee & Mike Pilkington, SANS DFIR Hunt Evil Poster — https://www.sans.org/posters/hunt-evil/
•	13Cubed, Windows Process Genealogy video, accessed via YouTube — https://www.youtube.com/watch?v=vpSIw-zGhhE
•	13Cubed, Windows Process Genealogy diagram — https://www.13cubed.com/downloads/windows_process_genealogy_v2.pdf
•	Linux man pages — https://man7.org/linux/man-pages/index.html
•	Linux nc man page — https://linux.die.net/man/1/nc
•	Wikipedia, Init — https://en.wikipedia.org/wiki/Init
•	Wikipedia, Runlevel — https://en.wikipedia.org/wiki/Runlevel
•	Novell, SUSE Linux Administration Guide, Section 13.4, Init Scripts — https://www.novell.com/documentation/suse91/suselinux-adminguide/html/ch13s04.html
•	Linux Foundation, Linux Standard Base Core Specification 4.1, Section 20.5, Run Levels
—	https://refspecs.linuxfoundation.org/LSB_4.1.0/LSB-Core-generic/LSB-Core- generic/runlevels.html
•	David Both, Understanding systemd at startup on Linux, published by opensource.com
—	https://opensource.com/article/20/5/systemd-startup
•	Wikipedia, File Allocation Table — https://en.wikipedia.org/wiki/File_Allocation_Table
•	Brien Posey, Windows file systems showdown: FAT16, FAT32, NTFS, and ReFS — https://searchwindowsserver.techtarget.com/answer/Whats-the-difference-between- FAT32-FAT16-and-NTFS
•	Wikipedia, NTFS — https://en.wikipedia.org/wiki/NTFS
•	Microsoft, Resilient File System (ReFS) overview — https://docs.microsoft.com/en- US/windows-server/storage/refs/refs-overview
•	Wikipedia, ReFS — https://en.wikipedia.org/wiki/ReFS
•	Jim Salter, Understanding Linux filesystems: ext4 and beyond, published by opensource.com — https://opensource.com/article/18/4/ext4-filesystem
 
•	Microsoft, Windows registry information for advanced users — https://docs.microsoft.com/en-us/troubleshoot/windows-server/performance/windows- registry-advanced-users
•	Wikipedia, Everything is a file — https://en.wikipedia.org/wiki/Everything_is_a_file
•	Gary Kessler, GCK’s FILE SIGNATURES TABLE —
https://www.garykessler.net/library/file_sigs.html
•	Wikipedia, Hash function — https://en.wikipedia.org/wiki/Hash_function
•	VirusTotal — https://www.virustotal.com/gui/home/search
